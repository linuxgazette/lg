<!DOCTYPE html
	PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
	 "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="utf-8" xml:lang="utf-8">
<head>
<title>
Linux Gazette : November 2009 (#168) 
</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<link href="../lg.css" rel="stylesheet" type="text/css" media="screen, projection" />

<style type="text/css" media="screen, projection">
<!--

.twdtarticle {
	width: 84%;
}

.twdtarticle h1 {
	font-size:19px;
	text-align:center;
}

.lgcontent {
        width: 84%;
        margin-top: 30px;
}

-->
</style>

</head>

<body id="twdtbody">

<a href="../">
<img src="../gx/2003/newlogo-blank-200-gold2.jpg" alt="Linux Gazette" id="twdtlogo"/>
</a>
<p id="fun">...making Linux just a little more fun!</p>

<div id="navigation">

<a href="../index.html">Home</a>
<a href="../faq/index.html">FAQ</a>
<a href="../lg_index.html">Site Map</a>
<a href="../mirrors.html">Mirrors</a>
<a href="../mirrors.html">Translations</a>
<a href="../search.html">Search</a>
<a href="../archives.html">Archives</a>
<a href="../authors/index.html">Authors</a>
<a href="http://lists.linuxgazette.net/mailman/listinfo/">Mailing Lists</a>
<a href="../jobs.html">Join Us!</a>
<a href="../contact.html">Contact Us</a>
</div>

<div id="breadcrumbs1">

<a href="../index.html">Home</a> &gt;
<a href="index.html">November 2009 (#168)</a> &gt;
TWDT

</div>


<div class="content lgcontent">

<h2>November 2009 (#168):</h2>

<ul>

	<li><a href="#lg_mail">Mailbag</a>

	<li><a href="#lg_talkback">Talkback</a>

	<li><a href="#lg_tips">2-Cent Tips</a>

	<li><a href="#lg_bytes">News Bytes</a>, by <i>Deividson Luiz Okopnik and Howard Dyckoff</i></li>

	<li><a href="#brownss">A Short CGI Script for Passing 404s to Another Server</a>, by <i>Silas Brown</i></li>

	<li><a href="#dyckoff1">Away Mission - Upcoming in November '09</a>, by <i>Howard Dyckoff</i></li>

	<li><a href="#nielsen">Setting up a MySQL Cluster for your Linux desktop</a>, by <i>Mark Nielsen</i></li>

	<li><a href="#silva">A 'revisited' guide to GNU Screen</a>, by <i>Anderson Silva and Steve 'Ashcrow' Milner</i></li>

	<li><a href="#collinge">HelpDex</a>, by <i>Shane Collinge</i></li>

	<li><a href="#ecol">Ecol</a>, by <i>Javier Malonda</i></li>

	<li><a href="#xkcd">XKCD</a>, by <i>Randall Munroe</i></li>

	<li><a href="#doomed">Doomed to Obscurity</a>, by <i>Pete Trbovich</i></li>

	<li><a href="#lg_launderette">The Linux Launderette</a>

</ul>

</div>



<br />


<div class="content lgcontent">

<a name="lg_mail"></a>
<h1>Mailbag</h1>

</b>
</p>

<p>
<h3>This month's answers created by:</h3><strong>[  Anderson Silva, Ben Okopnik, S. Parthasarathy, Kapil Hari Paranjape, Karl-Heinz Herrmann, Ren&eacute; Pfeiffer, Mulyadi Santosa, Neil Youngman, Rick Moen, Suramya Tomar, Mike Orr (Sluggo), Thomas Adam  ]</strong>
<br />...and you, our readers!<br /><hr width="50%" align="center" size="3" /><h1>Gazette Matters</h1>
<hr />

<!-- Thread anchor: Garbage mails in TAG --><a name='garbage_mails_in_tag'></a>
<h3>Garbage mails in TAG</h3>
<p>
<b><p>
Dr. Parthasarathy S [drpartha at gmail.com]

</p>
</b><br />
<b>Sun, 11 Oct 2009 08:51:40 +0530</b>
</p>

<p>
There is tooooo many garbage mails/spam mails in the TAG mailing list.
Can no one take some action ? Please filter out all garbage. Otherwise
people will stop reading or answering TAG mails.
</p>

<p>
Thank you,
</p>

<p>
partha
</p>

<pre>-- 
---------------------------------------------------------------------------------------------
Dr. S. Parthasarathy                    |   mailto:drpartha@gmail.com
Algologic Research &amp; Solutions    |
78 Sancharpuri Colony                 |
Bowenpally  P.O                          |   Phone: + 91 - 40 - 2775 1650
Secunderabad 500 011 - INDIA     |
WWW-URL: <a href='http://algolog.tripod.com/nupartha.htm'>http://algolog.tripod.com/nupartha.htm</a>
---------------------------------------------------------------------------------------------
</pre>

<p>

</p>

<p><b>[  <a name="mb-garbage_mails_in_tag"></a> <a href="misc/lg/garbage_mails_in_tag.html">Thread continues here (18 messages/26.82kB)</a>  ]</b></p>
<hr />

<h1>Our Mailbag</h1>
<hr />

<!-- Thread anchor: Disabling Gnome application sounds in KDE4 --><a name='disabling_gnome_application_sounds_in_kde4'></a>
<h3>Disabling Gnome application sounds in KDE4</h3>
<p>
<b><p>
Suramya Tomar [security at suramya.com]

</p>
</b><br />
<b>Sun, 25 Oct 2009 01:39:59 +0530</b>
</p>

<p>
Hey,
</p>

<p>
I recently installed Ubuntu 9.04 on my system and then installed KDE 
4.2.2 on the system using apt-get.
</p>

<p>
I don't like any system sounds (beeps when opening windows/ on popups 
etc etc) so I went to the KDE control panel and disabled all the system 
sounds over there. In KDE 3.5 this used to disable all sounds in Gnome 
applications as well but in 4.2.2 this doesn't seem to be the case.
</p>

<p>
So I ran the gnome Control panel and disabled all system sounds over 
there.  Now the problem is that this setting doesn't seem to be saved. 
Thus when I restart the system all the system sounds on gnome apps 
(Nautilus/Firefox/gedit/X-Chat etc) are back.
</p>

<p>
So how do I set it so that the sounds are disabled and stay that way 
over reboots?
</p>

<p>
Also the same issue is there with the fonts in the Gnome applications. 
The fonts in gnome applications (Size mainly) doesn't match the ones in 
KDE applications. I have to change them using the Gnome control panel 
and the changes don't stay saved.
</p>

<p>
Any idea's/Suggestions? I did try searching for solutions but none of 
the solutions suggested by google worked.
</p>

<p>
Let me know if you need any additional details.
</p>

<p>
- Suramya
</p>


<pre>-- 
-------------------------------------------------
Name : Suramya Tomar
Homepage URL: <a href='http://www.suramya.com'>http://www.suramya.com</a>
-------------------------------------------------
</pre>************************************************************
</p>

<p>

</p>

<p><b>[  <a name="mb-disabling_gnome_application_sounds_in_kde4"></a> <a href="misc/lg/disabling_gnome_application_sounds_in_kde4.html">Thread continues here (6 messages/7.23kB)</a>  ]</b></p>
<hr />


<!-- Thread anchor: Efficient chmod/chown --><a name='efficient_chmod_chown'></a>
<h3>Efficient chmod/chown</h3>
<p>
<b><p>
Mike Orr [sluggoster at gmail.com]

</p>
</b><br />
<b>Thu, 15 Oct 2009 11:18:15 -0700</b>
</p>

<p>
Is there a version of chmod/chown that recursively changes files only
if they're different from the specification?  The stock version
changes them unconditionally, which updates their 'ctime' and thus
makes 'rsync' transfer the inode properties even if there's no real
change.  I could write a Python version, but I was hoping there might
be a C version somewhere that would be more efficient with millions of
filenames.
</p>

<pre>-- 
Mike Orr &lt;sluggoster@gmail.com&gt;
</pre>

<p>

</p>

<p><b>[  <a name="mb-efficient_chmod_chown"></a> <a href="misc/lg/efficient_chmod_chown.html">Thread continues here (8 messages/8.34kB)</a>  ]</b></p>
<hr />


<!-- Thread anchor: Developing a small OS from a preinstalled Linux --><a name='developing_a_small_os_from_a_preinstalled_linux'></a>
<h3>Developing a small OS from a preinstalled Linux</h3>
<p>
<b><p>
Abhishek Sharma [spyzer.abhishek0 at gmail.com]

</p>
</b><br />
<b>Thu, 8 Oct 2009 20:17:07 +0530</b>
</p>

<p>
Hi,
</p>

<p>
I am working on a  project of making a small OS which will boot up on
my dual core machine and will serve as a simple calculator. If its
possible I would like to add GUI to it too.
</p>

<p>
My question is for this job do I need to program all the stuff as
assembly code or is there a way in which the precompiled linux kernel
or those "boot.img | initrd.img" can help me without having to go
through assembly development?
</p>

<p>
If its possible I would be glad if you tell me how I can achieve this.
</p>

<p>
Thank You.
</p>

<p>

</p>

<p><b>[  <a name="mb-developing_a_small_os_from_a_preinstalled_linux"></a> <a href="misc/lg/developing_a_small_os_from_a_preinstalled_linux.html">Thread continues here (7 messages/8.71kB)</a>  ]</b></p>
<hr />


<!-- Thread anchor: Followup: Regarding How can Define congestion windows in Fedora --><a name='followup__regarding_how_can_define_congestion_windows_in_fedora'></a>
<h3>Followup: Regarding How can Define congestion windows in Fedora</h3>
<p>
<b><p>
Predrag Ivanovic [predivan at nadlanu.com]

</p>
</b><br />
<b>Sun, 4 Oct 2009 16:02:27 +0200</b>
</p>

<p>
On Fri, 18 Sep 2009 23:06:39 -0500
</p>

<p>
&lt;forwarded message from Master of Technology&gt;
 
</p>

<pre>
&gt;i have some proble to define the
&gt;
&gt;1.Congestion  windows Size 2.algorithms. in NS-2 with Linux(Fedora)
&gt;
&gt;Thanking you.
&gt;
&gt;Mr. Brahm Deo sah
&gt;India
</pre>

<p>
<a href='http://lmgtfy.com/?q=Congestion+%20windows+Size+%20algorithms.+in+NS-2'>http://lmgtfy.com/?q=Congestion+%20windows+Size+%20algorithms.+in+NS-2</a>
</p>

<p>
Pedja
<pre>-- 
 improperly oriented keyboard
</pre>

<p>

</p>

<p><b>[  <a name="mb-followup__regarding_how_can_define_congestion_windows_in_fedora"></a> <a href="misc/lg/followup__regarding_how_can_define_congestion_windows_in_fedora.html">Thread continues here (3 messages/2.96kB)</a>  ]</b></p>
<hr />


<br clear="all" />

<script type='text/javascript'>
digg_url = 'http://linuxgazette.net/168/lg_mail.html';
digg_title = 'Mailbag';
digg_bodytext = '<p>In this month\'s Linux Gazette, \'Mailbag\' covers the following topics:<br>Garbage mails in TAG<br>Disabling Gnome application sounds in KDE4<br>Efficient chmod/chown<br>Developing a small OS from a preinstalled Linux<br>Followup: Regarding How can Define congestion windows in Fedora<br></p>';
digg_topic = 'linux_unix';
</script>
<script src="http://digg.com/tools/diggthis.js" type="text/javascript"></script>

</p>

<p class="talkback">
Talkback: <a
href="mailto:tag@lists.linuxgazette.net?subject=Talkback:168/lg_mail.html">Discuss this article with The Answer Gang</a>
</p>

<!-- *** BEGIN author bio *** -->
<!-- *** END author bio *** -->

<div id="articlefooter">


<p>
Published in Issue 168 of Linux Gazette, November 2009
</p>

</div>
</div>


<div class="content lgcontent">

<a name="lg_talkback"></a>
<h1>Talkback</h1>

</b>
</p>

<p>

<!-- Thread anchor: Talkback:167/okopnik.html --><a name='talkback_167_okopnik'></a>
<h3>Talkback:167/okopnik.html</h3>
<p><b>[ In reference to "<a href='../167/okopnik.html'>A Quick-Fire chroot Environment</a>" in LG#167 ]</b></p><p>
<b><p>
Jimmy O'Regan [joregan at gmail.com]

</p>
</b><br />
<b>Sun, 4 Oct 2009 15:56:58 +0100</b>
</p>

<p>
'as the "fortune" program says, "The best book on programming for the
layman is Alice in Wonderland; but that's because it's the best book
on anything for the layman."'
</p>

<p>
I think I laughed harder than I usually would have at this, because
I'd recently read a linguistics paper
(<a href='http://www.kwartjez.amu.edu.pl/Krazynska,%20Sloboda.pdf'>http://www.kwartjez.amu.edu.pl/Krazynska,%20Sloboda.pdf</a>) whose
'Further Reading' section contained, sandwiched between various works
about proto-Indo-European, a pointer to a translation of this very
book. It also happens that when asked by a friend if it were possible
to get old books in Polish and English text, and English audio, to be
the only book I could find legally in all three forms.
</p>

<p>
Curiouser and curiouser.
</p>

<p>

</p>

<hr />


<!-- Thread anchor: Talkback:128/saha.html --><a name='talkback_128_saha'></a>
<h3>Talkback:128/saha.html</h3>
<p><b>[ In reference to "<a href='../128/saha.html'>Coding a Simple Packet Sniffer </a>" in LG#128 ]</b></p><p>
<b><p>
Aisha S. Azim [aisha.s.azim at gmail.com]

</p>
</b><br />
<b>Tue, 6 Oct 2009 19:55:19 +0800</b>
</p>

<p>
On Tue, Oct 6, 2009 at 7:54 PM, Aisha S. Azim &lt;aisha.s.azim@gmail.com&gt;wrote:
</p>

<p>
Hi,
</p>

<p>
This tutorial is great, and so is sniffex.c. EXCEPT, it doesn't print the
payloads of packets when using UDP. Why ever not? It'll print out packet
number, source/destination, protocol, but never the hex/ascii payload and
header of the packet itself. Help!
</p>

<p>
Thanks
Aisha S. Azim
</p>

<p>

</p>

<hr />


<!-- Thread anchor: Talkback:160/okopnik.html --><a name='talkback_160_okopnik'></a>
<h3>Talkback:160/okopnik.html</h3>
<p><b>[ In reference to "<a href='../160/okopnik.html'>The Unbearable Lightness of Desktops: IceWM and idesk</a>" in LG#160 ]</b></p><p>
<b><p>
mrfrank [czechfox at sbcglobal.net]

</p>
</b><br />
<b>Sat, 03 Oct 2009 07:07:43 -0500</b>
</p>

<p>
ATTN:Ben Okopnik
</p>

<p>
	Just happened to run across the question in Linux Gazette Mar issue about
idesk. Just so happens I finally got idesk up a couple hrs ago using your  
info at <a href='../160/okopnik.html'>http://linuxgazette.net/160/okopnik.html</a>
then downloaded your idesk icon configurator. Small problem at this end.  
</p>

<p>
Instead of showing icons,
I get a series of 'Submit Query' in my browser. If I configure a link by  
clicking on one of the 'Submit Query's
it makes my link just fine, even giving me the complete path to the .png  
file &amp; the .png on the desktop link,
even though the icon itself is no shown in browser.
</p>

<p>
	This is a sample of the source code showing icon names;
</p>

<p>
<pre class='code'>
&lt;h3 style="background-color: blue; color: white; text-align: center"&gt;Click  
on an icon to create the IDesk link file&lt;/h3&gt;
&lt;input type="image" name="24x24/places/network-server.png"  
src="24x24/places/network-server.png" vspace="2" hspace="3" /&gt;
&lt;input type="image" name="24x24/places/folder-saved-search.png"  
src="24x24/places/folder-saved-search.png" vspace="2" hspace="3" /&gt;
&lt;input type="image" name="24x24/places/user-home.png"  
src="24x24/places/user-home.png" vspace="2" hspace="3" /&gt;
&lt;input type="image" name="24x24/places/gnome-fs-trash-empty.png"  
src="24x24/places/gnome-fs-trash-empty.png" vspace="2" hspace="3" /&gt;
</pre>
	I'm running icewm on unbuntu 9.04. Browser is firefox 3.08. Also Opera,  
but Opera shows a rectangle
with 'image' in it. If I copy the source and insert  
/home/xxxxxxx/.idesktop/builder/ into
<pre>
&lt;input type="image" name="24x24/places/user-home.png"  
src="24x24/places/user-home.png" vspace="2" hspace="3" /&gt;
</pre>

<p>
so it looks like this:
<pre class='code'>
&lt;input type="image" name="24x24/places/user-home.png"  
src="/home/xxxxxxx/.idesktop/builder/24x24/places/user-home.png"  
vspace="2" hspace="3" /&gt;
</pre>
the icon shows o.k.
	I don't know cgi, but I played around with idesk.cgi but can't figure out  
how to get the full path
to the .png files to show in the html.
</p>

<p>
	Any ideas how I can get the full path to show in the html?
</p>

<p>
	Thank you.
</p>

<p>
later
xxxxxxx
</p>

<p>

</p>

<p><b>[  <a name="mb-talkback_160_okopnik"></a> <a href="misc/lg/talkback_160_okopnik.html">Thread continues here (2 messages/3.64kB)</a>  ]</b></p>
<hr />


<br clear="all" />

<script type='text/javascript'>
digg_url = 'http://linuxgazette.net/168/lg_talkback.html';
digg_title = 'Talkback';
digg_bodytext = '<p>In this month\'s Linux Gazette, \'Talkback\' covers the following topics:<br>Talkback:167/okopnik.html<br>Talkback:128/saha.html<br>Talkback:160/okopnik.html<br></p>';
digg_topic = 'linux_unix';
</script>
<script src="http://digg.com/tools/diggthis.js" type="text/javascript"></script>

</p>

<p class="talkback">
Talkback: <a
href="mailto:tag@lists.linuxgazette.net?subject=Talkback:168/lg_talkback.html">Discuss this article with The Answer Gang</a>
</p>

<!-- *** BEGIN author bio *** -->
<!-- *** END author bio *** -->

<div id="articlefooter">


<p>
Published in Issue 168 of Linux Gazette, November 2009
</p>

</div>
</div>


<div class="content lgcontent">

<a name="lg_tips"></a>
<h1>2-Cent Tips</h1>

</b>
</p>

<p>

<!-- Thread anchor: 2-cent tip - rpath --><a name='2_cent_tip_rpath'></a>
<h3>2-cent tip - rpath</h3>
<p>
<b><p>
Oscar Laycock [oscar_laycock at yahoo.co.uk]

</p>
</b><br />
<b>Thu, 8 Oct 2009 02:17:44 -0700 (PDT)</b>
</p>

<p>
This all started when I wanted to run the latest version of Firefox. I
decided to build my own from source. But my kernel, assembler, compiler
and C library were too old - in fact, nine years old. So I built new
ones under the /usr/local directory. I used the Linux From Scratch book
as a guide.
</p>

<p>
Now when I build new programs, I set the GCC compiler's "rpath" option
to point to the libraries in /usr/local rather than in the usual /lib
and /usr/lib. The rpath is a list of libraries at the start of a program
that can tell Linux where to look for shared libraries when Linux runs a
program. A program called the "dynamic linker" does the job. On my
system it is "/lib/ld-linux.so.2". You can see a program's rpath by
running a command such as "readelf -a /bin/ls". Of course, normally
there isn't one. Also you can watch the dynamic linker at work using the
"ldd" command. I set GCC's rpath by including it in the CFLAGS
environment variable when configuring programs before building them.
(You typically type "configure", "make" and "make install" to build a
program.) I found a small number of programs ignore CFLAGS, so I made
the gcc program a shell script, which then calls the real gcc with the
right rpath option.
</p>

<p>
So I can now run old commands such as "ls" and "find" alongside new
programs such as the KDE suite. The now eleven-year-old commands run
fine on top of the recent kernel. I also put /usr/local/bin at the start
of my path. This may be a security risk but my PC is not connected to
the internet or a network.
</p>

<p>
There is a bit more too it. So here is the CFLAGS setting I used only
few days ago:
</p>

<p>
<pre class='code'>
export CFLAGS="-O2 -I. -I.. -I/usr/local/myglibc27/include -I/usr/local/include
-L/usr/local/myglibc27/lib -L/usr/local/lib -L/usr/local/lib/gcc/i686-pc-linux-gnu/4.2.3 -Wl,-rpath=/usr/local/myglibc27/lib:/usr/local/lib:/usr/local/lib/gcc/i686-pc-linux-gnu/4.2.3,-dynamic-linker=/usr/local/myglibc27/lib/ld-linux.so.2 -specs=/home/oscar/tmp/glibc/myspecs08scr -march=pentium2"
</pre>

<p>
I also similarly set these environment variables: LDFLAGS, CXXFLAGS,
CPPFLAGS, LIBCFLAGS, LIBCXXFLAGS. You can see that the include file path
(-I's) and libraries path (-L's) match the rpath. The "-I. -I.." is
there because some programs need to look at the header files in the
build directory first - a bit of a quick fix. Notice how I now have two
separate dynamic linkers on my PC. I had to edit the compiler specs file
a little. Here is a section to really confuse you:
</p>

<p>
<pre class='code'>
*startfile:
%{!shared: %{pg|p|profile:/usr/local/myglibc27/lib/gcrt1.o%s;pie:/usr/local/myglibc27/lib/Scrt1.o%s;:/usr/local/myglibc27/lib/crt1.o%s}}    /usr/local/myglibc27/lib/crti.o%s %{static:/usr/local/lib/gcc/i686-pc-linux-gnu/4.3.2/crtbeginT.o%s;shared|pie:/usr/local/lib/gcc/i686-pc-linux-gnu/4.3.2/crtbeginS.o%s;:/usr/local/lib/gcc/i686-pc-linux-gnu/4.3.2/crtbegin.o%s}
</pre>

<p>
I think this is choosing which C runtime code to put at the start of the program.
</p>

<p>
And here is the shell script that stands in for gcc:
<p>
[ ... ]
</p><p><b>[  <a name="mb-2_cent_tip_rpath"></a> <a href="misc/lg/2_cent_tip_rpath.html">Thread continues here (2 messages/4.00kB)</a>  ]</b></p>
<hr />


<!-- Thread anchor: Two-cent Tip: bash script to create animated rotating mark --><a name='two_cent_tip__bash_script_to_create_animated_rotating_mark'></a>
<h3>Two-cent Tip: bash script to create animated rotating mark</h3>
<p>
<b><p>
Mulyadi Santosa [mulyadi.santosa at gmail.com]

</p>
</b><br />
<b>Sat, 24 Oct 2009 16:34:04 +0700</b>
</p>

<p>
During my boring saturday, I was thinking to create simple animated
cycling mark. Here's the script:
</p>

<p>
<pre class='code'>
$ while(true); do for a in \\ \| \/ -; do echo -n $a; sleep 1 ; echo
-n -e \\r ; done; done
</pre>

<p>
Notice the usage of escaped "\r" (carriage return) and "-n" option to
display continous marks at the same line and at the same column
</p>

<pre>-- 
regards,
</pre>Freelance Linux trainer and consultant
</p>

<p>
blog: the-hydra.blogspot.com
training: mulyaditraining.blogspot.com
</p>

<p>

</p>

<p><b>[  <a name="mb-two_cent_tip__bash_script_to_create_animated_rotating_mark"></a> <a href="misc/lg/two_cent_tip__bash_script_to_create_animated_rotating_mark.html">Thread continues here (5 messages/5.54kB)</a>  ]</b></p>
<hr />


<!-- Thread anchor: 2-cent Tip: Load Python modules at Startup --><a name='2_cent_tip__load_python_modules_at_startup'></a>
<h3>2-cent Tip: Load Python modules at Startup</h3>
<p>
<b><p>
Amit Saha [amitsaha.in at gmail.com]

</p>
</b><br />
<b>Thu, 22 Oct 2009 18:49:49 +0530</b>
</p>

<p>
Hello:
</p>

<p>
I have been using CPython as a calculator, while I do all those number
crunching in C. SO, 'import math' is a must.
</p>

<p>
This is what I did:
</p>

<p>
- Create a file: .pythonrc in my $HOME and place this line:
</p>

<p>
<pre class='code'>
   import math
</pre>

<p>
- Now in your BASH, .bashrc or similar: export PYTHONSTARTUP= $HOME/.pythonrc
</p>

<p>
Everytime you start Python interactively, you should have the 'math'
module already imported.
</p>

<p>
<pre class='code'>
$ python
Python 2.6.4rc1 (r264rc1:75270, Oct 10 2009, 02:40:56)
[GCC 4.4.1] on linux2
Type "help", "copyright", "credits" or "license" for more information.
</p>

<pre>
&gt;&gt;&gt; math.pi
</pre>
3.1415926535897931
</pre>

<p>
Hope this helps.
</p>

<pre>-- 
Journal: <a href='http://amitksaha.wordpress.com'>http://amitksaha.wordpress.com</a>,
µ-blog: <a href='http://twitter.com/amitsaha'>http://twitter.com/amitsaha</a>
</pre>

<p>

</p>

<hr />


<!-- Thread anchor: Two-cent Tip: Detexify --><a name='two_cent_tip__detexify'></a>
<h3>Two-cent Tip: Detexify</h3>
<p>
<b><p>
Jimmy O'Regan [joregan at gmail.com]

</p>
</b><br />
<b>Wed, 14 Oct 2009 11:45:32 +0100</b>
</p>

<p>
<a href='http://detexify.kirelabs.org/classify.html'>http://detexify.kirelabs.org/classify.html</a>
</p>

<p>
Nifty website: draw the TeX symbol you were thinking of, and it tells
you which one it (probably) is. Source (MIT license) here:
<a href='http://github.com/kirel/detexify'>http://github.com/kirel/detexify</a>
</p>

<p>

</p>

<p><b>[  <a name="mb-two_cent_tip__detexify"></a> <a href="misc/lg/two_cent_tip__detexify.html">Thread continues here (3 messages/1.80kB)</a>  ]</b></p>
<hr />


<!-- Thread anchor: 2-cent Tip: Piping to GNU Plot from C --><a name='2_cent_tip__piping_to_gnu_plot_from_c'></a>
<h3>2-cent Tip: Piping to GNU Plot from C</h3>
<p>
<b><p>
Amit Saha [amitsaha.in at gmail.com]

</p>
</b><br />
<b>Sun, 4 Oct 2009 16:03:05 +0530</b>
</p>

<p>
Hello TAG:
</p>

<p>
Can this be a possible 2-cent tip?
</p>


<p>
Couple of things first up:
</p>

<p>
    * GNU plot supports piping, So, echo "plot sin(x)" | gnuplot will
plot the sin(x) function.
</p>

<p>
    * However, the plot disappears even before you could see it. For
that echo "plot sin(x)" | gnuplot -persist , is useful. It persists
the GNU plot main window
</p>

<p>
The usefulness of the second point is that, if you have a "pipe
descriptor" describing a pipe to the open GNU plot instance , you can
plot more plots on the first plot, without opening a new GNU plot
instance. We shall be using this idea in our code.
</p>

<p>
<pre class='code'>
#include &lt;stdio.h&gt;
#define GNUPLOT "gnuplot -persist"
 
int main(int argc, char **argv)
{
        FILE *gp;
        gp = popen(GNUPLOT,"w"); /* 'gp' is the pipe descriptor */
        if (gp==NULL)
           {
             printf("Error opening pipe to GNU plot. Check if you have it! \n");
             exit(0);
           }
 
        fprintf(gp, "set samples 2000\n");
        fprintf(gp, "plot abs(sin(x))\n");
        fprintf(gp, "rep abs(cos(x))\n");
        fclose(gp);
 
return 0;
}
</pre>

<p>
The above code will produce a comparative plot of absolute value of
sin(x) and cos(x) on the same plot.  The popen function call is
documented at <a href='http://www.opengroup.org/pubs/online/7908799/xsh/popen.html'>http://www.opengroup.org/pubs/online/7908799/xsh/popen.html</a>.
This code/idea should work on GCC and Linux and any other language and
OS that supports piping.
</p>

<p>
Utility: If you have a application which is continuously generating
some data, which you will finally plot, then you can plot the data for
every new set of data- that gives a nice visualization about how the
data is changing with the iterations of your application. This is a
perfect way to demonstrate convergence to the best solutions in
Evolutionary Algorithms, such as Genetic Algorithms.
</p>

<p>
Best,
Amit
</p>

<pre>-- 
Journal: <a href='http://amitksaha.wordpress.com'>http://amitksaha.wordpress.com</a>,
µ-blog: <a href='http://twitter.com/amitsaha'>http://twitter.com/amitsaha</a>
</pre>

<p>

</p>

<p><b>[  <a name="mb-2_cent_tip__piping_to_gnu_plot_from_c"></a> <a href="misc/lg/2_cent_tip__piping_to_gnu_plot_from_c.html">Thread continues here (4 messages/7.26kB)</a>  ]</b></p>
<hr />


<br clear="all" />

<script type='text/javascript'>
digg_url = 'http://linuxgazette.net/168/lg_tips.html';
digg_title = '2-Cent Tips';
digg_bodytext = '<p>In this month\'s Linux Gazette, \'2-Cent Tips\' covers the following topics:<br>2-cent tip - rpath<br>Two-cent Tip: bash script to create animated rotating mark<br>2-cent Tip: Load Python modules at Startup<br>Two-cent Tip: Detexify<br>2-cent Tip: Piping to GNU Plot from C<br></p>';
digg_topic = 'linux_unix';
</script>
<script src="http://digg.com/tools/diggthis.js" type="text/javascript"></script>

</p>

<p class="talkback">
Talkback: <a
href="mailto:tag@lists.linuxgazette.net?subject=Talkback:168/lg_tips.html">Discuss this article with The Answer Gang</a>
</p>

<!-- *** BEGIN author bio *** -->
<!-- *** END author bio *** -->

<div id="articlefooter">


<p>
Published in Issue 168 of Linux Gazette, November 2009
</p>

</div>
</div>


<div class="content lgcontent">

<a name="lg_bytes"></a>
<h1>News Bytes</h1>
<p id="by"><b>By <a href="../authors/dokopnik.html">Deividson Luiz Okopnik</a> and <a href="../authors/dyckoff.html">Howard Dyckoff</a></b></p>

</b>
</p>

<p>
<style type="text/css">
<!--
#news h2 { color: green; text-align: center; }
#news h3 { color: green; }
-->
</style>


<p>
<center>
<table cellpadding="7">
<tr>
<td>
<img src="../gx/bytes.gif" border="1" alt="News Bytes">
</td>
<td>
<h3>Contents:</h3>
<ul>
<li><a href="#general">News in General</a>
<li><a href="#Events">Conferences and Events</a>
<li><a href="#distro">Distro News</a>
</li><li><a href="#commercial">Software and Product News</a>
</ul>
</td>
</tr>
</table>
<strong>Selected and Edited by <a href="mailto:bytes@linuxgazette.net">Deividson Okopnik</a></strong>
</center>

<p style="font-style: italic"> Please submit your News Bytes items in
<strong>plain text</strong>; other formats may be rejected without reading.
[You have been warned!]  A one- or two-paragraph summary plus a URL has a
much higher chance of being published than an entire press release. Submit
items to <a
href="mailto:bytes@linuxgazette.net">bytes@linuxgazette.net</a>. Deividson can also be reached via <a href="http://www.twitter.com/deivid_okop">twitter</a>.</p>

<hr>

<div id="news">

<p>
<a name="general"></a>
<h2>News in General</h2>
<h3><img alt="lightning bolt" src="../gx/bolt.gif">Red Hat Urges Supreme Court to Exclude Patents to Software</h3>

<p>On October 1st, Red Hat filed an amicus brief with the United States
Supreme Court. In the brief, Red Hat explains the practical problems
of software patents to software developers. The brief, filed in the
Bilski case, asks the Supreme Court to adopt the lower court's
"machine-or-transformation" test and to make clear that it excludes
software from patentability.</p>

<p>The Bilski case involves the standard for patenting a process. The
case concerns a business method patent, but involves many of the same
issues as software patents.</p>

<p>"Red Hat continues its commitment to the free and open source software
community by taking a strong position against bad software patents,"
said Rob Tiller, vice president and assistant general counsel, IP for
Red Hat. "Our patent system is supposed to foster innovation, but for
open source and software in general, it does the opposite. Software
patents form a minefield that slows and discourages software
innovation. The Bilski case presents a great opportunity for the
Supreme Court to rectify this problem."</p>

<p>Patenting of software exploded in the 1990s based on judicial
decisions changing the test for patentable subject matter. Software
patents now number in the hundreds of thousands, and they cover
abstract technology in vague and difficult-to-interpret terms. Because
software products may involve thousands of patentable components,
developers face the risk of having to defend weak-but-costly patent
infringement lawsuits. A new class of business enterprise - patent
trolls - has developed to file lawsuits to exploit this system.</p>

<p>The Federal Circuit set forth a clear test to determine if a process
is patentable in stating that it must be either "tied to a particular
machine or apparatus" or must "transform a particular article into a
different state or thing." Red Hat argues that this standard is
consistent with Supreme Court case law, and that it should be applied
to exclude algorithms, including computer software, from patenting.</p>

<p>The scope of patentable subject matter is an issue of critical
importance to the future development of all software, including open
source. The upcoming Supreme Court's Bilski decision could clarify the
law and lessen the risks that innovation will be hindered by software
patents. Oral argument is scheduled for November 9, 2009.</p>

<p>Red Hat has supported patent reform to address problems posed to open
source and other software developers. It previously filed an amicus
brief in the Bilski case with the Federal Circuit Court of Appeals. To
read the full amicus brief, visit
<a href="http://www.redhat.com/f/pdf/rh-supreme-court-brief.pdf">http://www.redhat.com/f/pdf/rh-supreme-court-brief.pdf</a>.</p>

<h3><img alt="lightning bolt" src="../gx/bolt.gif">Linux Foundation
Announces Hardware Perks for Individual Members</h3>

<p>The Linux Foundation has announced new benefits for individual
members, including employee purchase pricing from Dell, HP and Lenovo,
and the opportunity to secure a Linux.com email address for life.</p>

<p>Linux Foundation individual members can get up to 40 percent off of
Lenovo devices and standard employee purchase pricing from Dell and
HP. Dell also offers a best price guarantee to Linux Foundation
members. These benefits can translate into hundreds or thousands of
dollars for those who purchase their devices as part of this program.</p>

<p>Existing members that would like to ensure their Linux.com email
address is permanent and not dependent on Linux Foundation membership
renewal can elect to secure it with a one-time $150 fee. New members
who want the same benefit will pay a total of $249 for the first year'
membership and the lifetime benefit. Linux.com email addresses allow
members to publicly represent their support for Linux and to
demonstrate their community participation.</p>

<p>"Our individual members are the heartbeat of the Linux Foundation and
we will continue to find ways to extend special benefits to them,"
said Jim Zemlin, executive director at the Linux Foundation. "Perks
like the employee purchase discounts from Dell, HP and Lenovo and
lifetime Linux.com email addresses are unique things we can offer to
sustain support for Linux."</p>

<p>The annual membership fee for individuals is $99. Students can also
now become members with a student-class membership for $25 annually.</p>

<p>Other discounts and benefits available to individual members
include:</p>
<ul>
<li> 30% discount on the Linux Foundation' LinuxCon and Japan Linux
Symposium events;<br />
<li> 20% discount on registration fees for Linux Foundation training 
courses;<br />
<li> 35% off O'Reilly books and e-Books;<br />
<li> 35% off No Starch Press Publications;<br />
<li> 15% off subscriptions to Linux Journal;<br />
<li> $10 off every $40 order on ThinkGeek.com;<br />
<li> a free Linux Foundation t-shirt for proclaiming support for Linux; <br />
<li> a weekly "Linux Briefing Book" in the form of an exclusive email with
highlighted news and analysis to keep users well informed.</ul>

<p>To join the Linux Foundation or to see a full list of benefits and
discounts, visit their membership page:
<a href="http://www.linuxfoundation.org/about/join/individual/">http://www.linuxfoundation.org/about/join/individual/</a>
.</p>

<h3><img alt="lightning bolt" src="../gx/bolt.gif">Moblin 2 on new Netbooks</h3>

<p>Demonstrating industry momentum for netbooks and the Moblin operating
system, Renee James, general manager of Intel's Software and Services
Group, announced at IDF that the Dell Inspiron Mini 10v with would be
available with Ubuntu Moblin Remix Developer Edition pre-installed.
James also announced that ASUS and Acer have already launched and Samsung
is planning to launch Moblin 2-based netbook devices. Many operating
system vendors, including Canonical, CS2C, Linpus, Mandriva, Novell,
Phoenix and Turbolinux, announced at IDF that production-ready Moblin
version 2-based operating systems are now available. Moblin is an
open-source Linux operating system project for netbooks, handhelds,
smartphones and in-car computers.</p>

<p>Additionally, operating system support for Microsoft Silverlight will
be expanded to include Moblin early next year. Using Silverlight's
cross-platform foundation, developers can write applications once and
have them run on both Windows and Moblin devices.</p>

<p>In the same IDF keynote, James unveiled the Intel Atom Developer
Program. This effort encourages independent software vendors and
developers to create mobile applications. Intel is partnering with
manufacturers, including Acer and ASUS, to create multiple application
stores (like the iPhone store) where applications and application
building blocks for Atom-based netbooks and handhelds will be sold.</p>
<hr>

<a name="links"></a>
<h2>Conferences and Events</h2>
<p>
<dl> <dt> <strong>LISA '09 - 23rd Large Installation System Administration Conference</strong> <dd>
November 1-6, Marriott Waterfront Hotel, Baltimore, MD<br />
<a href="http://www.usenix.org/lisa09/proga">http://www.usenix.org/lisa09/proga</a>.</dl>

<dl> <dt> <strong>Cloud Computing & Virtualization 2009</strong> <dd>
November 2-4, Santa Clara Convention Center, Santa Clara, CA<br />
<a href="https://www3.sys-con.com/cloud1109/registernew.cfm">https://www3.sys-con.com/cloud1109/registernew.cfm</a>.</dl>

<dl> <dt> <strong>iPhone Developer Summit</strong> <dd>
November 2-4, Santa Clara, CA<br />
<a href="http://www.iphonedevsummit.com">http://www.iphonedevsummit.com</a>.</dl>

<dl> <dt> <strong>Enterprise 2.0 Fall 2009</strong> <dd>
November 2-5, Moscone Center, San Francisco, CA<br />
<a href="http://www.e2conf.com/sf">http://www.e2conf.com/sf</a>.</dl>

<dl> <dt> <strong>VoiceCon-SF 2009</strong> <dd>
November 2-5, Moscone Center, San Francisco, CA<br />
<a href="http://www.voicecon.com/sanfrancisco/">http://www.voicecon.com/sanfrancisco/</a>.</dl>

<dl> <dt> <strong>ApacheCon</strong> <dd>
November 2-6, Oakland, CA<br />
<a href="http://us.apachecon.com/">http://us.apachecon.com/</a>.</dl>

<dl> <dt> <strong>2nd Annual Linux Foundation End User Summit</strong> <dd>
November 9-10, Jersey City, NJ<br />
<a href="http://events.linuxfoundation.org/events/end-user-summit">http://events.linuxfoundation.org/events/end-user-summit</a>.</dl>

<dl> <dt> <strong>OPP and APEXposed 2009</strong> <dd>
November 10-11, Sheraton Airport, Atlanta, GA<br />
<a href="http://odtugopp.com/register.htm">http://odtugopp.com/register.htm</a>.</dl>

<dl> <dt> <strong>Interop New York</strong> <dd>
November 16-20, New York, NY<br />
<a href="http://www.interop.com/newyork/">http://www.interop.com/newyork/</a>.</dl>

<dl> <dt> <strong>Web 2.0 Expo New York</strong> <dd>
November 16-19, New York, NY<br />
<a href="http://en.oreilly.com/webexny2008">http://en.oreilly.com/webexny2008</a>.</dl>

<dl> <dt> <strong>KmWorld & Intranets Conference</strong> <dd>
November 17-19, San Jose, CA<br />
<a href="https://secure.infotoday.com/forms/default.aspx?form=kmw2009&priority=PDE145">https://secure.infotoday.com/forms/default.aspx?form=kmw2009&priority=PDE145</a>.</dl>

<dl> <dt> <strong>QCon Conference 2009</strong> <dd>
November 18-20, Westin Hotel, San Francisco, CA<br />
<a href="http://qconsf.com/sf2009/">http://qconsf.com/sf2009/</a>.</dl>

<dl> <dt> <strong>10th ACM/USENIX International Middleware Conference</strong> <dd>
November 30-December 4, Urbana Champaign, IL<br />
<a href="http://middleware2009.cs.uiuc.edu/">http://middleware2009.cs.uiuc.edu/</a>.</dl>

<dl> <dt> <strong>Gartner Data Center Conference 2009</strong> <dd>
December 1-4, Caesar's Palace, Las Vegas, NV<br />
<a href="http://www.gartner.com/us/datacenter">http://www.gartner.com/us/datacenter</a>.</dl>
</p>

<hr>

<a name="distro"></a>
<h2>Distro News</h2><h3><img alt="lightning bolt" src="../gx/bolt.gif">Ubuntu 9.10 Desktop, Server and UNR Editions Released</h3>

<p>Canonical released Ubuntu 9.10 Desktop Edition and Server Edition, the
latest version of its popular Linux distribution, for free download on
October 29th.  The 9.10 version of its UNR (Ubuntu Netbook Remix) OS is
also available.  This is the OS version previously known as Karmic
Koala.</p>

<p>Ubuntu 9.10 Desktop features a redesigned, faster boot and login
experience, a revamped audio framework, Firefox 3.5, and improved 3G
broadband connectivity, all of which contribute to a first-class user
experience.</p>

<p>With its '100 Paper Cuts' initiative to allow users to nominate minor
annoyances that impacted their enjoyment of the platform, over 50
fixes have been committed, removing minor irritants such as
inconsistent naming or poorly organized application choices. Larger
scale user experience improvements include a refreshed Ubuntu Software
Centre, giving users better information about the software they have
available.</p>

<p>Ubuntu 9.10 also includes the integration of 'Ubuntu One' as a
standard component of the desktop. Ubuntu One is an umbrella name for
a suite of online services released in beta in May 2009. Ubuntu One
simplifies backup, synchronization, and sharing of files with features
such as Tomboy Notes and contacts synchronization.</p>

<p>Developers interested in writing applications that run on Ubuntu now
have a simplified toolset called 'Quickly' which automates many
mundane programming tasks. Quickly also helps users 'package' the code
and distribute it through the Ubuntu software repositories. Ubuntu
developers will now find all code hosted in the Bazaar version control
system, which is part of the fully open source Launchpad collaboration
website.</p>

<p>Netbook and smartbook users will find improvements to the Ubuntu 9.10
Netbook Remix interface. Common with Ubuntu 9.10 for desktops UNR will
integrate the Empathy instant messaging program for text, voice,
video, and file transfers.</p>

<p>"Ubuntu 9.10 gives users more reasons than ever to seriously consider
Linux at a time when many are thinking again about their operating
system options. We are delivering a platform for users interested in
an easy-to-use, great-looking, Web-friendly operating system" says
Jane Silber, COO at Canonical.</p>

<p>At the press conference before the 9.10 release, Mark Shuttleworth, CEO
and founder of Canonical, remarked that he was "delighted Windows 7 was
out," and that, "now we can engage in a real head to head competition."
Shuttleworth added that after OEMs were using Linux on netbooks and smaller
devices they have "seen the advantage with having more than one OS vendor
and don't want to return to having only one choice."  Shuttleworth said he
expected Linux to continue to dominate in mobile devices because Windows 7
varients would be too expensive. He aslo noted that hardware OEMs were
doing a better job of supporting Linux, especially after Intel's efforts
with Moblin.</p>

<h4>Ubuntu 9.10 Server Edition: Cloud Computing made Easier</h4>

<p>Ubuntu 9.10 Server Edition introduces Ubuntu Enterprise Cloud (UEC) as a
fully supported technology. This is an open source cloud computing
environment, based on the same Application Programming Interfaces (APIs) as
Amazon EC2, and allows businesses to build private clouds.  Canonical CEO
and Ubuntu founder Mark Shuttleworth began highlighting the embedded cloud
tools during the spring of this year.  Ubuntu 9.10 Server Edition will also
be available on the Amazon EC2 environment as an Amazon Machine Image
(AMI). For the purpose of portability, Ubuntu's UEC images are identical to
Ubuntu's AMI, and work done in one environment can be uploaded to the
other.</p>

<p>Ubuntu Enterprise Cloud (UEC) is the umbrella name for a number of cloud
technologies, which includes the open source Eucalyptus project.  UEC makes
it easy and fast for system administrators to set up, deploy and manage a
cloud environment. Users familiar with Elastic Compute environments will be
able to build similar infrastructure behind their firewall, avoiding many
regulatory and security concerns that prevent many enterprises from taking
advantage of cloud environments. UEC also provides a tight integration with
power management tools such as the new Canonical-sponsored PowerNap project
which allows servers to be put to sleep when they are not actively
used.</p>

<p>Ubuntu Enterprise Cloud is preparing a store capability that will
provide users with easy access to ready-to-deploy applications in the
UEC environment. A first preview of this store is available in Ubuntu
9.10, together with a sample application. It will demonstrate
solutions to software vendors and additional applications will be
added after the release.</p>

<p>The core server product and kernel have also received significant
attention in this release. MySQL 5.1 has been added. The directory
stack and Single Sign On tools have been upgraded for improved
directory integration. Django now ships as a fully supported framework
enhancing web server options.</p>

<p>There have been numerous kernel improvements to better support both Xen
(guest) and KVM (host and guest) virtualization, and to improve caching
performance. Support for the USB 3.0 protocol has been included to support
super speed transfer rates when devices become available. System management
support has been extended through support for the WBEM (Web-based
enterprise management) protocols which open up support of the Ubuntu
environment to the most popular system management tools currently deployed
in enterprises and allows them to interact more easily with Canonical's
management tool for Ubuntu, called Landscape.</p> <p>Ubuntu Enterprise Cloud
is included as part of Ubuntu 9.10 Server Edition. Landscape Server
Management System is available at <a
href="http://www.canonical.com/projects/landscape">http://www.canonical.com/projects/landscape</a>.</p>

<p>Earlier press reports erroneously listed Ubuntu 9.10 as having early
support for the new USB 3.0 standards.  This support is actually planned
for the next release.</p>

<p>Ubuntu Desktop and Server Editions and UNR are entirely free of charge
and can be downloaded from <a
href="http://www.ubuntu.com">http://www.ubuntu.com</a> .  Ubuntu One offers
2 GB storage for free, and 50 GB for $10 per month.</p>

<p>The 100 Paper Cuts project can be found here:
<a href="https://edge.launchpad.net/hundredpapercuts/">https://edge.launchpad.net/hundredpapercuts/</a>.<br />
The list of UNR supported netbooks can be found here
<a href="https://wiki.ubuntu.com/HardwareSupport/Machines/Netbooks/">https://wiki.ubuntu.com/HardwareSupport/Machines/Netbooks/</a>.<br />
For more information, please visit <a href="http://www.canonical.com">http://www.canonical.com</a>.</p>

<h3><img alt="lightning bolt" src="../gx/bolt.gif">OpenBSD 4.6 now out</h3>
<p>OpenBSD 4.6 was released in October, a little earlier than expected. A
few of the enhancements are noted here:</p>

<p>Generic Network-Stack improvements:</p>
<ul>
<li> Support for virtual routing and firewalling with the addition of
routing domains;<br />
<li> Wireless interfaces have an interface priority of 4 by default,
which makes them less preferred then wired interfaces;<br />
<li> Does not accept IPv4 ICMP redirects by default<br />
<li> Added the MAC address to the log entries in dhclient(8).</ul>

<p>New platform support:</p>
sparc64:<br />
<ul>
<li> Added acceleration support for many of the PCI frame buffer 
drivers, such as Sun PGX, PGX64 and XVR-100, and Tech Source Raptor GFX
graphics cards;<br />
<li> Added support for virtual network switches.<br />
</ul>
sgi:<br />
<ul>
<li> Added support for the SGI Octane, SGI Origin 200 and SGI Fuel
families of systems.</ul>

<h3><img alt="lightning bolt" src="../gx/bolt.gif">Puppy Linux 4.3.1</h3>
<p>A new release of Puppy Linux 4.3.1, a bug-fix update of the recently
released version 4.3, appeared in October. Some of the fixes and
changes include: New modem drivers and improved modem detection; fixes
for CD remaster script; Asunder CD ripper replaces Ripoff; You2pup,
fix for spaces in paths; DidiWiki personal Wiki upgraded to 0.8; JWM
window manager upgraded to revision 457; NicoEdit, secondary text
editor, upgraded to 2.4; etc.</p>

<h3><img alt="lightning bolt" src="../gx/bolt.gif">Mandriva Linux 2010 RC2</h3>
<p>The second release candidate for Mandriva Linux 2010 is now available
on public mirrors.  Mandriva Linux 2010 should be available in early
November.</p>

<p>Besides bug fixes, it also includes Moblin, KDE 4.3.2, GNOME 2.28,
Poulsbo, a guest account, and Nepomuk.</p>


<h3><img alt="lightning bolt" src="../gx/bolt.gif">openSUSE 11.2 RC1 available</h3>
<p>The first release candidate for openSUSE 11.2, which is due in
mid-November,  is now ready for testing. This release includes  bug
fixes and updates, including GNOME 2.28 final and Linux kernel
2.6.31.3.  The new version includes: live version upgrade - no need to
stop working while upgrading from openSUSE 11.1 to 11.2; support for
several social networks like Facebook, Twitter and identi.ca; and
running openSUSE from an USB stick.</p>


<h3><img alt="lightning bolt" src="../gx/bolt.gif">Tiny Core Linux updated</h3>
<p>Tiny Core Linux is a very small (10 MB) minimal Linux desktop. It is
based on Linux 2.6 kernel, BusyBox, Tiny X, FLTK graphical user
interface and JWM window manager, running entirely in memory.  The
goal is the creation of a nomadic ultra-small desktop capable of
booting from cdrom, pendrive, or frugally from a hard drive.</p>

<p>It is not a complete desktop, nor is all hardware completely
supported. It represents only the core needed to boot into a very
minimal X Window desktop, typically with wired Internet access. This
minimal desktop can be extended by installing additional applications
from online repositories.  For more info, see:
<a href="http://www.tinycorelinux.com/">http://www.tinycorelinux.com/</a>.</p>

<a name="commercial"></a>
<hr>
<h2>Software and Product News</h2>
<h3><img alt="lightning bolt" src="../gx/bolt.gif">JetBrains' IntelliJ IDEA Goes Open Source</h3>
<p>JetBrains, the creators of productivity tools for software developers,
announced announced in October the public preview of the free
Community Edition of its award-winning Java IDE, IntelliJ IDEA.</p>

<p>Starting with the upcoming version 9.0, IntelliJ IDEA will be offered in
two editions: Community Edition, free and open-source, and Ultimate
Edition, which until October was simply IntelliJ IDEA.</p>

<p>The introduction of the Community Edition removes cost as a major
barrier to a wider use of IntelliJ IDEA for pure Java development.
This edition is not only free, its also fully open-sourced.</p>

<p>"We've always been open to the community - with our public Early Access
Program, issue trackers, forums, and so on. This made for a tight and
direct feedback loop with our users, even at a time when this wasn't a
widely accepted practice in the industry. Since then, we've supported
hundreds of open-source projects with free product licenses, contributed
code to various open-source projects like Groovy and Scala, and developed
several open-sourced IntelliJ IDEA plugins ourselves," said Sergey
Dmitriev, JetBrains CEO.  "So, you can see how offering the IntelliJ IDEA
experience for free, through an open-source license, goes hand in hand with
our focus on the community. Open source has become the mainstream, and we
continue to embrace it as an exciting challenge."</p>

<p>The new Community Edition is built on the IntelliJ Platform and includes
its sources. JetBrains has made it as easy as possible to access and use the
source code of the Community Edition and the IntelliJ Platform, by applying the
democratic Apache 2.0 license to both of them.</p>

<p>The IntelliJ Platform serves as a basis for a wide range of other
innovative JetBrains tools, designed for development in specific
languages and/or domains. These tools include RubyMine, MPS, a web
development IDE (already in public preview), and others currently in
development.</p>

<p>IntelliJ split the two editions based on a functional principle:</p>
<ul>
<li>Community Edition is for those working on pure Java/Groovy
applications or doing Swing development. It has all the crown jewels
of IntelliJ IDEA, including various refactorings and code inspections,
coding assistance, debugging, TestNG and JUnit testing; CVS,
Subversion and Git support, as well as Ant and Maven build
integration.
 
<li>Ultimate Edition is a full-featured commercial IntelliJ IDEA with the
complete set of web and enterprise development tools, traditionally 
providing
top-quality support for the most important modern technologies and 
frameworks.
</ul>

<p>The new features of Ultimate Edition version 9 include: </p>
<ul>
<li> Java EE 6, with JSF 2.0, JPA 2.0, Servlets 3.0, Bean validation, 
etc; <br />
<li> Android, Google App Engine, GWT; <br />
<li> Adobe AIR, FlexUnit; <br />
<li> JavaScript refactorings and debugging; <br />
<li> Tapestry, OSGi, PHP; <br />
<li> Tight Perforce, ClearCase and Microsoft Team Foundation integration.</ul>

<p>To review the extended list of new features of IntelliJ IDEA Ultimate 
9, and to download the Preview build, please visit
<a href="http://www.jetbrains.com/idea/nextversion/index.html">http://www.jetbrains.com/idea/nextversion/index.html</a>.</p>

<p>To learn more and download the Community Edition Public Preview, 
please visit
<a href="http://www.jetbrains.com/idea/nextversion/free_java_ide.html">http://www.jetbrains.com/idea/nextversion/free_java_ide.html</a>.</p>

<p>Read about the differences between the Community Edition and the 
Ultimate Edition at 
<a href="http://www.jetbrains.com/idea/nextversion/editions_comparison_matrix.html">http://www.jetbrains.com/idea/nextversion/editions_comparison_matrix.html</a>.</p>

<p>Learn more about the open source project for IntelliJ IDEA Community 
Edition and download its sources at <a href="http://www.jetbrains.org">http://www.jetbrains.org</a>.</p>


<h3><img alt="lightning bolt" src="../gx/bolt.gif">Dell Latitude Z-ltraPortable with Business Features</h3>
<p>The Dell Latitude Z is the claimed to be world's first ultra-thin
16-inch laptop that is less than an inch thick and starts at 4.5 pounds
with a standard four-cell battery. The system includes:</p>

<ul><li> Lean tapered design and soft-touch Black Cherry finish; <br />
<li> The world' first laptop with wireless docking and inductive charging;<br />
<li> Dell' EdgeTouch allows users to interact with commonly used
applications and media controls through a touch interface that is on
the bezel of the system' screen;<br />
<li> Multi-touch touchpad and backlit keyboard;<br />
<li> A high-definition (1600x900) WLED display and two megapixel camera;<br />
<li> Dell FaceAware Lock-Out automatically locks out others users when a
user steps away;<br />
<li> Laptop bags by Cole Haan and Timbuck2 designed specifically for the
Latitude Z;<br />
<li> WLAN, Bluetooth and optional 3G WWAN mobile broadband.</ul>

<p>The Latitude Z is available starting at $1,999. More details are
available at <a href="http://www.dell.com/latitude">http://www.dell.com/latitude</a>.</p>


<h3><img alt="lightning bolt" src="../gx/bolt.gif">Smallest Wireless N USB Adapter Now Available from TRENDnet</h3>
<p>TRENDnet has released what is possibly the world's smallest 150Mbps
Mini Wireless N USB Adapter, its model TEW-648UB product. The ultra
compact form factor is slightly larger than a U.S. quarter, measuring
a remarkable 1.3 inches (3.3 cm) from end to end.</p>

<p>The 150Mbps Mini Wireless N USB Adapter connects a laptop or desktop
computer to a wireless 'n' network at up to 6x the speed and 3x the
coverage of a wireless 'g' connection. One-touch Wi-Fi Protected Setup
or WPS technology eliminates the hassle of entering complicated codes
in order to connect to a wireless network.</p>

<p>Advanced wireless encryption protects your valuable data. Wi-Fi
Multimedia (WMM) Quality of Service prioritizes important video, audio
and gaming traffic to create a premium wireless experience.</p>

<blockquote>"We have looked high and low and are confident in our claim that the
	TEW-648UB is the smallest adapter on the market today. In fact it is
	half the size of the average wireless N USB adapter.", stated Zak
	Wood, Director of Global Marketing for TRENDnet. "Despite its
	diminutive size, it performs well. We welcome all independent tests
	against any other 150Mbps (or 1x1) adapter on the market today. The
	adapter features an equally small price tag.  With a predicted street
	price in the low $20 range, this adapter sets a new
	price-to-performance standard."</blockquote>

	<p>The 150Mbps Mini Wireless N USB Adapter, model TEW-648UB, has an MSRP
of US $24.99.</p>

</div>

<hr>


<br clear="all" />

<script type='text/javascript'>
digg_url = 'http://linuxgazette.net/168/lg_bytes.html';
digg_title = 'News Bytes';
digg_bodytext = '<p>In this month\'s Linux Gazette, \'News Bytes\' covers the following topics:<br>Contents:<br>Red Hat Urges Supreme Court to Exclude Patents to Software<br>Moblin 2 on new Netbooks<br>Ubuntu 9.10 Desktop, Server and UNR Editions Released<br>Ubuntu 9.10 Server Edition: Cloud Computing made Easier<br>OpenBSD 4.6 now out<br>Puppy Linux 4.3.1<br>Mandriva Linux 2010 RC2<br>openSUSE 11.2 RC1 available<br>Tiny Core Linux updated<br>JetBrains\' IntelliJ IDEA Goes Open Source<br>Dell Latitude Z-ltraPortable with Business Features<br>Smallest Wireless N USB Adapter Now Available from TRENDnet<br></p>';
digg_topic = 'linux_unix';
</script>
<script src="http://digg.com/tools/diggthis.js" type="text/javascript"></script>

</p>

<p class="talkback">
Talkback: <a
href="mailto:tag@lists.linuxgazette.net?subject=Talkback:168/lg_bytes.html">Discuss this article with The Answer Gang</a>
</p>

<!-- *** BEGIN author bio *** -->
	<hr>
<p>
<img align="left" alt="[BIO]" src="../gx/authors/dokopnik.jpg" class="bio">
</p>

<em>
<p>
Deividson was born in Uni&atilde;o da Vit&oacute;ria, PR, Brazil, on
 14/04/1984. He became interested in computing when he was still a kid,
 and started to code when he was 12 years old. He is a graduate in
 Information Systems and is finishing his specialization in Networks and
 Web Development. He codes in several languages, including C/C++/C#, PHP,
 Visual Basic, Object Pascal and others.
</p>

<p>
Deividson works in Porto Uni&atilde;o's Town Hall as a Computer
 Technician, and specializes in Web and Desktop system development, and
 Database/Network Maintenance.
</p>



</em>

<br clear="all">


	<!-- *** BEGIN bio *** -->
<hr>
<p>

<img align="left" alt="Bio picture" src="../gx/authors/dyckoff.jpg" class="bio">

<em>
<p>
Howard Dyckoff is a long term IT professional with primary experience at
Fortune 100 and 200 firms. Before his IT career, he worked for Aviation
Week and Space Technology magazine and before that used to edit SkyCom, a
newsletter for astronomers and rocketeers. He hails from the Republic of
Brooklyn [and Polytechnic Institute] and now, after several trips to
Himalayan mountain tops, resides in the SF Bay Area with a large book
collection and several pet rocks.
</p>

<p>
Howard maintains the <a
href="http://technology-events.blogspot.com">Technology-Events</a> blog at
blogspot.com from which he contributes the Events listing for Linux
Gazette. Visit the blog to preview some of the next month's NewsBytes
Events.
</p>

</em>
<br clear="all">
<!-- *** END bio *** -->

<!-- *** END author bio *** -->

<div id="articlefooter">


<p>
Copyright &copy; 2009, <a href="../authors/dokopnik.html">Deividson Luiz Okopnik</a> and <a href="../authors/dyckoff.html">Howard Dyckoff</a>. Released under the
<a href="http://linuxgazette.net/copying.html">Open Publication License</a>
unless otherwise noted in the body of the article. Linux Gazette is not
produced, sponsored, or endorsed by its prior host, SSC, Inc.
</p>


<p>
Published in Issue 168 of Linux Gazette, November 2009
</p>

</div>
</div>


<div class="content lgcontent">

<a name="brownss"></a>
<h1>A Short CGI Script for Passing 404s to Another Server</h1>
<p id="by"><b>By <a href="../authors/brownss.html">Silas Brown</a></b></p>

</b>
</p>

<p>
<p>
There are several reasons why you might have more than
one website.  For example, you might have an account on a
fast server with limited quota, and another on a server
that is slower but has more space, and you keep certain
rarely-used files on the slower server.  Or you might
have an easy-to-remember dyndns alias pointing to your
home server, but some pages on another server that has a
better connection but a longer address.  If this is the
case, then it might be useful to set one of the servers
to forward any requests for pages it can't find to the
other server.  Then you can use this first server in all
the addresses you type, and if the page requested is on
it, it will be returned, otherwise the browser will be
automatically redirected to check the second server for
the same page.  (Don't set that second server to redirect
back to the first or you'll have an infinite loop.)
</p>

<p>
Using Apache, this can be accomplished as follows.
Firstly, put the following line into your
<tt>public_html/.htaccess</tt> file, replacing
<tt>/~your-user-ID</tt> as appropriate (if you have your
own hostname then you can omit it):
</p>

<pre>
ErrorDocument 404 /~your-user-ID/cgi-bin/redirect.cgi
</pre>

<p>
This tells Apache to run the script whenever it would
normally issue a 404.  If you want the redirection to take effect for
index.html also (that is if index.html is missing), then you should also add:
</p>

<pre>
Options -Indexes
ErrorDocument 403 /~your-user-ID/cgi-bin/redirect.cgi
</pre>

<p>
This prevents directory listing, and tells Apache to
send the browser to the redirection script instead of
showing the "Forbidden" message.  This arrangement might be useful if your main
site is on the other server but this server contains a
few extra files that you want Apache to check for first.
</p>

<p>
Then create <tt>public_html/cgi-bin/redirect.cgi</tt>
as follows, replacing <tt>other-site-address-goes-here</tt>
and <tt>~your-user-ID</tt> as appropriate:
</p>

<pre>
#!/bin/bash
echo Status: 301 Moved
echo Location: "$(echo "$REQUEST_URI"|sed -e s,/,http://other-site-address-goes-here/, -e s,~your-user-ID/,,)"
echo
</pre>

<p>
Then <tt>chmod +x public_html/cgi-bin/redirect.cgi</tt> and test.
</p>

<p>
The above script should work regardless of whether or
not <tt>~your-user-ID</tt> is included in the request,
that is, if Apache is serving your <tt>public_html</tt>
on your own hostname then this script should work
regardless of whether the incoming request is for your
hostname or for your user ID on the main hostname.
</p>

<p>
Some antiquated browsers might not follow the 301
redirect.  If this is a concern then you can add some
text in the response as well.  But the script as it
stands is small and easily set up, and should work
without trouble in most cases.
</p>


<br clear="all" />

<script type='text/javascript'>
digg_url = 'http://linuxgazette.net/168/brownss.html';
digg_title = 'A Short CGI Script for Passing 404s to Another Server';
digg_bodytext = '<p> There are several reasons why you might have more than one website.  For example, you might have an account on a fast server with limited quota, and another on a server that is slower but has more space, and you keep certain rarely-used files on the slower server.  Or you might have an easy-to-remember dyndns alias pointing to your home server, but some pages on another server that has a better connection but a longer address.  If this is the case, then it might be useful to set one of the servers to forward any requests for pages it can\'t find to the other server.  Then you can use this first server in all the addresses you type, and if the page requested is on it, it will be returned, otherwise the browser will be automatically redirected to check the second server for the same page.  (Don\'t set that second server to redirect back to the first or you\'ll have an infinite loop.) </p> ';
digg_topic = 'linux_unix';
</script>
<script src="http://digg.com/tools/diggthis.js" type="text/javascript"></script>

</p>

<p class="talkback">
Talkback: <a
href="mailto:tag@lists.linuxgazette.net?subject=Talkback:168/brownss.html">Discuss this article with The Answer Gang</a>
</p>

<!-- *** BEGIN author bio *** -->
	<hr>
<p>
<img align="left" alt="[BIO]" src="../gx/authors/brownss.jpg" class="bio">
</p>

<em>
<p>
Silas Brown is a legally blind computer scientist based in Cambridge UK.
 He has been using heavily-customised versions of Debian Linux since
 1999.
</p>



</em>

<br clear="all">


<!-- *** END author bio *** -->

<div id="articlefooter">


<p>
Copyright &copy; 2009, <a href="../authors/brownss.html">Silas Brown</a>. Released under the
<a href="http://linuxgazette.net/copying.html">Open Publication License</a>
unless otherwise noted in the body of the article. Linux Gazette is not
produced, sponsored, or endorsed by its prior host, SSC, Inc.
</p>


<p>
Published in Issue 168 of Linux Gazette, November 2009
</p>

</div>
</div>


<div class="content lgcontent">

<a name="dyckoff1"></a>
<h1>Away Mission - Upcoming in November '09</h1>
<p id="by"><b>By <a href="../authors/dyckoff.html">Howard Dyckoff</a></b></p>

</b>
</p>

<p>
<p>
It's nearly time to retire 2009, yet many conferences for the Linux and
open source community are just about to happen. A plethora will happen
in the first week of November, so this preview may give you ideas for
2010.
</p>

<p>
Here's a short list of what's on offer:
</p>


<dl> 
<dt><strong>LISA '09 - 23rd Large Installation System Administration 
Conference</strong>
<dd>Nov 1-6, 2009, Marriott Waterfront Hotel, Baltimore, MD<br />
<a href="http://www.usenix.org/events/lisa09/">http://www.usenix.org/events/lisa09/</a>
</dl>

<dl>
<dt><strong>Cloud Computing &amp; Virtualization 2009</strong>
<dd>Nov 2-4, Santa Clara Convention Center, Santa Clara, CA<br />
<a href="https://www3.sys-con.com/cloud1109/registernew.cfm">https://www3.sys-con.com/cloud1109/registernew.cfm</a>
</dl>

<dl>
<dt><strong>iPhone Developer Summit</strong>
<dd>Nov 2-4, Santa Clara, CA<br />
<a href="http://www.iphonedevsummit.com/">http://www.iphonedevsummit.com/</a>
</dl>

<dl>
<dt><strong>Enterprise 2.0 Fall 2009</strong>
<dd>Nov 2-5, Moscone Center, San Francisco, CA<br />
<a href="http://www.e2conf.com/sanfrancisco/">http://www.e2conf.com/sanfrancisco/</a>
</dl>

<dl>
<dt><strong>VoiceCon-SF 2009</strong>
<dd>Nov 2-5, 2009, San Francisco<br />
<a href="http://www.voicecon.com/sanfrancisco/">http://www.voicecon.com/sanfrancisco/</a>
</dl>

<dl>
<dt><strong>ApacheCon</strong>
<dd>Nov. 2-6, Oakland, CA<br />
<a href="http://us.apachecon.com/c/acus2009/">http://us.apachecon.com/c/acus2009/</a>
</dl>

<dl>
<dt><strong>2nd Annual Linux Foundation End User Summit</strong>
<dd>Nov 9-10, 2009, Jersey City, NJ<br />
<a href="http://events.linuxfoundation.org/events/end-user-summit/">http://events.linuxfoundation.org/events/end-user-summit/</a>
</dl>

<dl>
<dt><strong>QCon - San Francisco</strong>
<dd>Nov 18-20, SF, CA<br />
<a href="http://qconsf.com/sf2009/">http://qconsf.com/sf2009/</a>
</dl>


<p>
As you may know, the <strong>End User Summit</strong> organized by the
Linux Foundation is by invitation only.  The event is closed to the
press, as was the first summit, in 2008.  The Summit is primarily an
opportunity for big corporate end-users to meet with leaders from within
the Linux community, including the highest-level maintainers and
developers. The event was originally created at the request of the Linux
Foundation's Technical Advisory Board.  
</p>

<p>
The Summit will take place November 9-10, 2009, at the Hyatt Jersey City on
the Hudson. Its location, just off the Exchange Place PATH Station, will
give corporate Linux users quick access from East Coast hubs.
</p>

<p>
There will be sessions on open source legal fronts, Linux and the
challenges of a down economy, tracing and performance management,
scaling Linux to 4096 processors, and other technical sessions. 
</p>

<p>
<strong>LISA '09</strong>, the annual sysadmin conference organized
by USENIX, starts the month off in Baltimore.  Locals in the
Baltimore-DC area can get the new LISA Evening Pass. This allows access
after work for conference receptions, the Vendor Exhibition on Wednesday
only, the popular Birds of a Feather sessions (BoFs), and more.  
</p>

<p>
There will be sessions on cfEngine, VMware vSphere 4.0, and
zero-emission data centers.  Cutting-edge practices and new or developing
work are presented in the paper presentations and the poster sessions.
Check out the list of accepted posters at
<a href="http://www.usenix.org/events/lisa09/posters.html">http://www.usenix.org/events/lisa09/posters.html</a>. Also, all registered
LISA '09 attendees are eligible to received a Google Wave Sandbox
invitation.
</p>

<p>
Here's an overview of LISA '09:
<a href="http://www.usenix.org/events/lisa09/ataglance.html">http://www.usenix.org/events/lisa09/ataglance.html</a>
</p>

<p>
Here's a link to past LISA conference proceedings:
<a href="http://www.usenix.org/events/bytopic/lisa.html">http://www.usenix.org/events/bytopic/lisa.html</a>
</p>


<p>
<strong>ApacheCon '09</strong> will be held in Oakland, CA; this year is
also the 10th anniversary of the Apache Foundation. The venue is the
Marriott City Center Hotel (and that's a very safe location).  Last year,
it was held in New Orleans.  
</p>

<p>
The first 2 days include half-day tutorials.  There are also several
free events paralleling the conference tutorial days, including the
Hackathon and the BarCamps. 
</p>

<p>
<strong>Apache Hackathon</strong> is held over the two days prior to the
main three-day conference, November 2-3, and everyone can join in this
free codefest event.  Coinciding with the traditional Hackathon,
<strong>BarCampApache</strong> is open to the public, and the schedule
will be determined by the participants.  Topics at BarCampApache need
not be Apache-specific.  
</p>

<p>
Here's a conference overview:
<a href="http://www.us.apachecon.com/c/acus2009/schedule/grid/">http://www.us.apachecon.com/c/acus2009/schedule/grid/</a>
</p>

<p>
There will be several BoFs or MeetUps at ApacheCon '09, and the current
list is here: <a href="http://www.us.apachecon.com/c/acus2009/schedule/meetups/">http://www.us.apachecon.com/c/acus2009/schedule/meetups/</a>
</p>


<p>
Video recordings from the keynotes at last year's ApacheCon are here:
<a href="http://streaming.linux-magazin.de/en/archive_apachecon08us.htm">http://streaming.linux-magazin.de/en/archive_apachecon08us.htm</a>
</p>


<p>
The theme for <strong>Enterprise 2.0</strong> San Francisco is
"unlocking the business value of Enterprise 2.0", with an emphasis on
how real customers are using enterprise 2.0 social media to enable a
more efficient, agile, and highly productive workforce.  
</p>

<p>
Conference topics include, among others: 
</p>

<ul>
<li>Social Networking in Business 
<li>Social Networks as New Media 
<li>Social Messaging &amp; Twitter 
<li>Enterprise Mash-ups 
<li>Enterprise Software 
<li>Enterprise RSS &amp; Syndication 
</ul>

<p>
Since this is a new conference, you might want to take a quick look at
the keynotes from June's Enterprise 2.0 conference in Boston:
<a href="http://www.e2conf.com/e2tv/">http://www.e2conf.com/e2tv/</a>
</p>

<p>
Enterprise 2.0 San Francisco is held jointly with VoiceCon, at the
Moscone Center this year.  Registration for one event allows access to
the other.
</p>


<p>
<strong>QCon SF</strong>. This is the third annual San Francisco
incarnation of the enterprise software development conference, and its
focus is on developer team leads, architects and agile project
management.  This is primarily an open source conference, and has
separate Ruby and Java tracks.  
</p>

<p>
Organized jointly by the JAOO conference and the InfoQ.com Enterprise
Software Development Community (original creators of TheServerSide.com
and Symposium conferences), QCon is "...organized by the community, for
the community."
</p>

<p>
One unique aspect of QCon is its Euro-centric origins.  Many - but not
most - of the speakers are leading developers and architects from
Europe, and QCon is a great opportunity to meet peers from across the
Atlantic without a passport and plane ticket.  The global prospective is
refreshing, and there is no overbearing presence of giant software
vendors.  All content, no spin.
</p>

<p>
QCon speakers include Martin Fowler, Amazon.com CTO Werner Vogels,
Spring creator Rod Johnson, Hibernate creator Gavin King, Scrum
co-founder Jeff Sutherland, LINQ inventor Erik Meijer, JRuby core
developer Ola Bini, and others.
</p>

<p>
Here's a list of the conference tracks by day:
<a href="http://qconsf.com/sf2009/tracks/">http://qconsf.com/sf2009/tracks/</a>
</p>

<p>
And here's a link to the archives from prior QCons, so you can see for
yourself: <a href="http://qcon.infoq.com/archives/">http://qcon.infoq.com/archives/</a>
</p>

<p>
Happy Thanksgiving, and a Happy New Year to all!
</p>


<br clear="all" />

<script type='text/javascript'>
digg_url = 'http://linuxgazette.net/168/dyckoff1.html';
digg_title = 'Away Mission - Upcoming in November \'09';
digg_bodytext = '<p> It\'s nearly time to retire 2009, yet many conferences for the Linux and open source community are just about to happen. A plethora will happen in the first week of November, so this preview may give you ideas for 2010. </p> ';
digg_topic = 'linux_unix';
</script>
<script src="http://digg.com/tools/diggthis.js" type="text/javascript"></script>

</p>

<p class="talkback">
Talkback: <a
href="mailto:tag@lists.linuxgazette.net?subject=Talkback:168/dyckoff1.html">Discuss this article with The Answer Gang</a>
</p>

<!-- *** BEGIN author bio *** -->
	<!-- *** BEGIN bio *** -->
<hr>
<p>

<img align="left" alt="Bio picture" src="../gx/authors/dyckoff.jpg" class="bio">

<em>
<p>
Howard Dyckoff is a long term IT professional with primary experience at
Fortune 100 and 200 firms. Before his IT career, he worked for Aviation
Week and Space Technology magazine and before that used to edit SkyCom, a
newsletter for astronomers and rocketeers. He hails from the Republic of
Brooklyn [and Polytechnic Institute] and now, after several trips to
Himalayan mountain tops, resides in the SF Bay Area with a large book
collection and several pet rocks.
</p>

<p>
Howard maintains the <a
href="http://technology-events.blogspot.com">Technology-Events</a> blog at
blogspot.com from which he contributes the Events listing for Linux
Gazette. Visit the blog to preview some of the next month's NewsBytes
Events.
</p>

</em>
<br clear="all">
<!-- *** END bio *** -->

<!-- *** END author bio *** -->

<div id="articlefooter">


<p>
Copyright &copy; 2009, <a href="../authors/dyckoff.html">Howard Dyckoff</a>. Released under the
<a href="http://linuxgazette.net/copying.html">Open Publication License</a>
unless otherwise noted in the body of the article. Linux Gazette is not
produced, sponsored, or endorsed by its prior host, SSC, Inc.
</p>


<p>
Published in Issue 168 of Linux Gazette, November 2009
</p>

</div>
</div>


<div class="content lgcontent">

<a name="nielsen"></a>
<h1>Setting up a MySQL Cluster for your Linux desktop</h1>
<p id="by"><b>By <a href="../authors/nielsen.html">Mark Nielsen</a></b></p>

</b>
</p>

<p>

<ol>
<li><a href="#intro">Introduction</a>
</li>
<li><a href="#row">Row Level Replication and why it frustrates me</a>
</li>
<li><a href="#setup">Misc Setup</a>
</li>
<li><a href="#general">General Approach</a>
</li>
<li><a href="#config">Configuration Files</a> 
</li>
<li><a href="#install">Installing MySQL Cluster on Ubuntu</a> 
</li>
<li><a href="#rep">Setting up and Testing Replication to a Slave and Cluster Slave</a> 
</li>
<li><a href="#test">Let's test MySQL</a> 
</li>
<li><a href="#sp">Installing Stored procedure on Slaves and Masters</a>
</li>
<li><a href="#con">Conclusion and Future Topics</a>
</li>
<li><a href="#ssd">Some SSD preliminary testing</a>
</li>
</ol>
<hr>
<h2><a name="intro"></a>Introduction</h2>

<p>
MySQL Cluster has come a long way in the 4 years since I experimented with
it. Compared to when I first got the cluster working on my home computer, I
didn't have to change much get the latest version up and running.
</p>

<p>
So, what is MySQL Cluster? It is a database solution which tries to
solve high availability issues by using multiple synchronous masters (for
the lack of a better phrase) in a shared-nothing environment. In order to
solve a lot of the latency issues associated with multiple masters, it
keeps all the indexed data in memory to enable fast processing of the data.
</p>

<p>
So then what is the purpose of this article? To let you setup a MySQL
Cluster for fun, on a single box, so you can test out its features<sup>1</sup>.
The main things I wanted to test out are:
</p>
<ul>
<li>Setting up a cluster on one or two boxes. People tell me this is
impossible.  For personal and business reasons, this article attempts to
squash those rumors so I can just point people to this article instead of
explaining the details to them.  There are advantages to setting up a
cluster on 3 boxes as compared to 2 boxes, however. There is a difference
between a network outage and a single server becoming unavailable and 3
servers help with this.
</li>
<li>Using other storage engines and setup dangerous replication between the
frontend MySQL servers.  </li>
<li>Replicating data to a cluster slave as well as a normal slave. </li>
</ul>

<p>
There is also one important item to keep in mind about MySQL Cluster. I
have no idea why they make "MySQL Cluster" as a separate product from the
main MySQL server. In the past, the "MySQL Cluster" was just the NDB engine
running in MySQL. It seems to be the same way even now and I suspect that
it might just be due to politics and marketing that they have something
called a "MySQL Cluster" when it is really just MySQL with the NDB engine.
The mysqld server running in "MySQL Cluster" can still store data in InnoDB
and MyISAM formats. </p>

<p>For more info about MySQL Cluster, refer to:
</p>

<ul>
<li><a href="http://dev.mysql.com/doc/refman/4.1/en/mysql-cluster.html">http://dev.mysql.com/doc/refman/4.1/en/mysql-cluster.html</a>
</li>
<li><a href="http://www.mysql.com/products/database/cluster/">http://www.mysql.com/products/database/cluster/</a>
</li>
<li>For non-cluster MySQL, I highly recommend the "percona" version.
I'd like to see a MySQL Cluster supported version of MySQL. Download
MySQL from <a href="http://www.percona.com/docs/wiki/release:start">http://www.percona.com/docs/wiki/release:start</a>
</li>
</ul>
The MySQL Cluster uses these types of servers:
<ol>
<li>Data Node: Where all the data is stored. </li>
<li>MySQL frontend server: The MySQL frontend doesn't store any data
itself (unless you really want it to, like I do). It handles the processing
of the queries and gets the data from the data nodes. </li>
<li>Management Node: Manages all the nodes. </li>
</ol>
I highly recommend that you view the limitations of MySQL Cluster. If you
are used to using InnoDB, you will need to change some practices.
<ul>
<li>Read the <a
href="http://dev.mysql.com/doc/refman/5.1/en/mysql-cluster-limitations.html">Limitations</a>.
</li>
<li>Specifically:
<a href="http://dev.mysql.com/doc/refman/5.1/en/mysql-cluster-limitations-unsupported-missing.html">http://dev.mysql.com/doc/refman/5.1/en/mysql-cluster-limitations-unsupported-missing.html</a>
</li>
<li>Statement level replication:
<a href="http://dev.mysql.com/doc/refman/5.1/en/mysql-cluster-replication-general.html">http://dev.mysql.com/doc/refman/5.1/en/mysql-cluster-replication-general.html</a>
</li>
<li>MySQL Cluster replication issues:
<a href="http://mirror.facebook.net/mysql/doc/refman/5.1/en/mysql-cluster-replication-issues.html">http://mirror.facebook.net/mysql/doc/refman/5.1/en/mysql-cluster-replication-issues.html</a>
</li>
</ul>
<hr>
<h2><a name="row"></a>Row Level Replication and why it frustrates me</h2>
Please read <a
href="http://dev.mysql.com/doc/refman/5.1/en/replication-sbr-rbr.html">Comparison
of Statement-Based and Row-Based Replication</a>.
<p>MySQL copies data from one computer to another computer through
MySQL Replication. The old way of replicating data was to copy over and
execute all the SQL commands from one MySQL server to the other MySQL
servers. This type of replication was called "Statement Level
Replication.". This copying and executing of queries was NOT real-time
and had some issues. Basically, it was like this:
</p>
<ul>
<li>Query is executed on the master. Let's say the query took 30
seconds to finish. </li>
<li>Query is saved to a log and then each slave server downloads the
query. There is a time delay in downloading the query. Usually it isn't
very much. </li>
<li>Query gets executed on the slave servers. From the point the slaves
start to execute the query, they will take an equal amount of time to
execute the query as the master did. If the master took 30 seconds to
execute an insert, update, or delete command, it will take 30 seconds for
each slave to do the same (usually). Thus, right before a slave finishes
the 30 second query, it is behind in replication by 30 seconds, or rather
its data won't be in sync until 30 seconds later (after the query is
finished). </li>
</ul>

<p>
For most practical purposes, most small queries finish very fast and
replication is also very fast.
</p>

<p>So what is Row level Replication? Basically, the SQL query which
executes the changes on the master is forgotten and we only record the
actual row differences and copy them over. For example, let us say that
a query updates a table and sets the country code to 'US' for all
entries that are NULL. In a table with 1 million rows, let's say only
10 rows were NULL and thus 10 rows get updated. The difference between
Statement and Row Level Replication is the following:
</p>
<ul>
<li>Statement Replication will copy the query and execute it.</li>
<li>Row Replication will copy only the changes for those 10 rows and
ignore what the original query is.
</li>
</ul>
<p>Row Level Replication doesn't care what the SQL query was. It only
looks at the data that has changed and copies those changes to the
slaves. </p>
<p>Why does this frustrate me? For a few reasons:
</p>
<ol>

<li>Everything is moving towards Row Level Replication and Statement Level
Replication is being made incompatible under some conditions. I think both
are very powerful and you should let the end user decide what they want to
use. I understand that Statement Level Replication can cause problems
(under some circumstances), so my attitude is that they should work around
the problems. The power retained by keeping both as an option at all times
is the ability to customize how you do things. I have been in many
situations where a slight improvement in performance meant a big deal.
Thus, you want all your options open.</li>

<li>Also, Row Level Replication is MUCH HARDER to debug. Statement Level
Replication is very easy to debug. I have seen weird replication issues
with MySQL in the past and I don't like to be in a situation where I can't
debug things easily. Everything about being a DBA is debugging database
problems and finding out where the problem is.  All the advantages of Row
Level Replication are almost irrelevant if you can't debug issues in
replication.</li>

</ol>

<p> I am glad we have Row Level Replication as an option and it can be nice
to use depending on your needs.  I just wish Statement Level Replication
could be used if handled correctly under all all configurations. To give
you a better perspective of why Statement Level Replication is nice to
debug, we had a weird case one time where 1 byte in a replication stream
would change for no reason over a WAN. If it changed in the data, nobody
would notice (that's really bad). But if it changed in one of the SQL
words, replication would break. We were easily able to compare the master's
binlogs to the slave's binlogs and find out what the problem was. I remain
sceptical how easy it will be to verify why things break with row level
replication. Maybe I am just paranoid, but you have to be when managing
databases. </p>

<hr>
<h2><a name="setup"></a>Misc Setup</h2>
I have two systems I am using to test MySQL Cluster on.
<ul>
<li>First computer: Laptop with 3 GB of RAM running Ubuntu.
</li>
<li>Second computer: Desktop with 2 GB of RAM running Ubuntu 9
and also using a Vortex SSD hard drive. I have an external drive
enclosure so I could test the SSD hard drive on other systems. 
</li>
<li>Third system: 2 GB server with CentOS. 
</li>
</ul>
Some things to NOTE: 
<ul>
<li> It's interesting to note I only get a max of 30 MB/sec transfer rate from
my laptop hard drive to the Vortex drive. I think it's because of the speed
of USB and also the internal hard drive. I've read that USB 2.0 maxes out
at 40 MB/sec. In theory, if I attach the Vortex drive directly to the
motherboard on my desktop computer, it should go a lot faster. In case you
wonder why I am mentioning this, at the time of this article, the Intel
X25-e SSD drive looks very promising in regard to database use. I expect
that 90% of the databases using MySQL will be using SSD drives in the next
few years, because most MySQL servers have less than 100 GB of data. Also,
the SSD hard drives will get faster and bigger. I bought the Vortex because
it was cheaper and I just wanted to test SSD out in general and later use
it for my laptop. If it works out well, I'll buy the Intel X25-e and put it
in my desktop and beat the daylights out of it running database
simulations. </li>
<li>Also, when I connected the Vortex SSD hard drive to the motherboard
on my desktop, I could only get about 35 MB/sec written to the
SSD hard drive when reading files from cache. It seems to go faster
than the new 1.5 TB SATA hard drive I bought though, which was about 23 MB/sec 
if I remember right. </li>
<li>Have a Gb free of diskspace. You don't need all of that, maybe
300 MB at most. </li>
<li>Of course, you should have Python installed. You don't really need
Python installed for anything in this article, but you should have it
installed anyways. (<a href="http://xkcd.com/353/">353</a>, <a
href="http://xkcd.com/413/">413</a>, <a href="http://xkcd.com/409/">409</a>,
<a href="http://xkcd.com/521/">521</a>, <a href="http://xkcd.com/482/">482</a>)
</li>
</ul>


And also, add these IP addresses to your system:
<pre>
/sbin/ifconfig lo:1 127.0.0.101 netmask 255.0.0.0
/sbin/ifconfig lo:2 127.0.0.102 netmask 255.0.0.0
/sbin/ifconfig lo:3 127.0.0.103 netmask 255.0.0.0
/sbin/ifconfig lo:4 127.0.0.104 netmask 255.0.0.0
</pre>
<p>


As a side note, it is interesting to see how Ubuntu is taking off on the desktop 
market and how it is starting to creep into the server market. For me, I just like to 
use the same operating system for the desktops and servers because then I know that
the operating system is flexible and can work under multiple environments. 
After all, isn't a desktop just a server running Xwindows with OpenOffice and FireFox?
To me, the words "desktop" and  "server" are just marketing terms. 

<hr>
<h2><a name="general"></a>General Approach</h2>
The goal of setting up a MySQL Cluster is to make sure that if any node
goes down, a backup node can take over. This is true for all the
nodes including the management node. What is
the minimum number of servers you need for a redundant MySQL Cluster?
Two. People often
claim that the management node needs its own server, which is totally BOGUS.
You can have backup management nodes. Also, a management node doesn't
do anything most of the time, so if you use a separate server for the
management node, it is a waste.
<p>Here's the setup for our article:
</p>
<ol>
<li>Add 4 IP addresses to your box: 127.0.0.101, 127.0.0.102,
127.0.0.103, 127.0.0.104. This can be accomplished through standard linux
networking commands. </li>
<li>For each IP address, bind a data node, mysqld node, and
management node to its default ports. Each IP address will have its own
set of nodes. </li>
<li>One management node will be a backup management node. </li>
<li>Define NDB databases with a prefix to make it easy to separate
NDB databases from InnoDB and MyISAM databases. </li>
<li>Setup replication between the MySQL servers on 127.0.0.101
and 127.0.0.102 in dual master mode excluding replication of the NDB
databases (the cluster takes care of the NDB databases). </li>
<li>Setup replication to a cluster slave and a normal slave using Row
Level Replication. You could do Statement Level Replication, but then
all writes would have to go to exactly one of the mysqld servers in the
Cluster. </li>
</ol>
<table SUMMARY="Replication Summary" border="1">
<tbody>
<tr>
<th>&nbsp;</th>
<th colspan="5">Replication Type</th>
<th>Row Level<br>
Replication </th>
<th>Special<br>
Rep Config</th>
<th>Hacks<br>
necessary</th>
<th>Problems</th>
<th>Notes</th>
<th>Weird Purpose </th>
</tr>
<tr>
<th>&nbsp;</th>
<th>Cluster</th>
<th>Other<br>
Engines</th>
<th>MySQLD<br>
Master<br>
Replication</th>
<th>Slave</th>
<th>Cluster<br>
Slave</th>
<th colspan="10">&nbsp;</th>
</tr>
<tr>
<td>1.</td>
<td align="center">&bull; </td>
<td> &nbsp; </td>
<td> &nbsp; </td>
<td> &nbsp; </td>
<td> &nbsp; </td>
<td>&nbsp; </td>
<td>&nbsp;</td>
<td>&nbsp;</td>
<td>&nbsp;</td>
<td>Basic configuration.</td>
</tr>
<tr>
<td>2.</td>
<td align="center">&bull; </td>
<td align="center">&bull; </td>
<td> &nbsp; </td>
<td> &nbsp; </td>
<td> &nbsp; </td>
<td>&nbsp;</td>
<td>&nbsp;</td>
<td>&nbsp;</td>
<td>1 </td>
<td>Non-ndb data is split across mysqld nodes</td>
<td>1</td>
</tr>
<tr>
<td>3.</td>
<td align="center">&bull; </td>
<td align="center">&bull; </td>
<td align="center">&bull; </td>
<td> &nbsp; </td>
<td> &nbsp; </td>
<td>Y </td>
<td> Y </td>
<td> Y </td>
<td>2</td>
<td>Can use other storage engines. </td>
<td>1</td>
</tr>
<tr>
<td>5.</td>
<td align="center">&bull; </td>
<td align="center">&bull; </td>
<td align="center">&bull; </td>
<td align="center">&bull; </td>
<td> &nbsp; </td>
<td>Y </td>
<td>Y </td>
<td>Y</td>
<td>2</td>
<td>Convert tables to non-NDB tables on Slave.</td>
<td>1,2</td>
</tr>
<tr>
<td>6.</td>
<td align="center">&bull; </td>
<td> &nbsp; </td>
<td> &nbsp; </td>
<td> &nbsp; </td>
<td align="center">&bull; </td>
<td>Y </td>
<td>&nbsp; </td>
<td>&nbsp;</td>
<td>&nbsp;</td>
<td>Standard Cluster Replication.</td>
</tr>
<tr>
<td>7.</td>
<td align="center">&bull; </td>
<td align="center">&bull; </td>
<td align="center">&bull; </td>
<td> &nbsp; </td>
<td align="center">&bull; </td>
<td>Y </td>
<td> Y </td>
<td> Y </td>
<td>2</td>
<td>Cluster Replication with non-NDB tables.</td>
<td>1</td>
</tr>
<tr>
<td>8.</td>
<td align="center">&bull; </td>
<td align="center">&bull; </td>
<td align="center">&bull; </td>
<td align="center">&bull; </td>
<td align="center">&bull; </td>
<td>Y </td>
<td> Y </td>
<td>Y </td>
<td>2</td>
<td>Convert replication to non-NDB tables on Slave.</td>
<td>1,2</td>
</tr>
</tbody>
</table>
<ul>
<li>Special Rep Config: The MySQLd nodes need to replicate non-NDB
data. </li>
<li>Hacks Necessary: The stored procedure I use is needed to start
replication if a MySQLd node gets restarted. </li>
</ul>
<p>
Problems:
</p>
<ol>
<li>Inconsistent data on non-NDB tables.
</li>
<li>Replication configurations are needed to avoid duplicate entries
in the binlogs. Non-NDB data replicated on the MySQLd servers will
need to be setup in a Replication Circle. </li>
</ol>
<p>
Weird Purposes:
</p>
<ol>
<li>Keep log data out of cluster to keep the data small in the
cluster.
</li>
<li>Use Read-Repeatable mode in InnoDB on the normal slave. This can
be useful for *snapshot* reports. </li>
</ol>
<hr>
<h2><a name="config"></a>Configuration Files</h2>
Place all of these files in "/etc/mysql".
I make NO APOLOGIES for the configuration of these files. I haven't
finished tuning the configurations yet. I just did the bare minimum to get
it to work. Use at your own risk.
<ul>
<li>There is one "config.ini" file which is needed by all the
servers. It is here: <a href="files/etc/config.ini.txt">config.ini.txt</a>.
</li>
<li>MySQL config file for Master1 mysql node1 server. It is here: <a
href="files/etc/my.cnf_node1.txt">my.cnf_node1.txt</a>.
</li>
<li>MySQL config file for Master2 mysql node2 server. It is here: <a
href="files/etc/my.cnf_node2.txt">my.cnf_node2.txt</a>.
</li>
<li>MySQL config file for Slave1 mysql server. It is here: <a
href="files/etc/my.cnf_slave1.txt">my.cnf_slave1.txt</a>.
</li>
<li>Cluster Slave1 config.ini file. It is here: <a
href="files/etc/config.ini_cslave1.txt">config.ini_cslave1.txt</a>.
</li>
<li>MySQL config file for Cluster Slave1 mysql server. It is here: <a
href="files/etc/my.cnf_cslave1.txt">my.cnf_cslave1.txt</a>.
</li>
</ul>
<p>
These files I use to stop and start MySQL. I put it in
/usr/local/mysql_cluster.
</p>
<ul>
<li>Commands I used to setup MysQL. It is here: <a
href="files/restart_cluster.sh.txt">commands.txt</a>.
</li>
</ul>
<hr>
<h2><a name="install"></a>Installing MySQL Cluster on Ubuntu</h2>
Compile and install OR download.
<p>There are 3 ways to install MySQL: Do-It-Yourself, get it from a 3rd party, or
from
MySQL. It is unlikely that the official website for MySQL will have consistent
downloads for Ubuntu versions. We'll see if things change in the
future. You have two real options: Download and compile it yourself or
download from a third party. I'll explain both here:
</p>
<h3> Download and Install MySQL </h3>
Download my <a href="files/cfiles.tgz">config files</a> and untar
them.
<pre>tar -zxvf cfiles.tgz</pre>
It should be safe to download and untar them in the working source
directory of MySQL right after you have downloaded and untarred the
source code for MySQL.
<p>Note: The download steps below only work for a specific version of
MySQL. Please refer to
<a target="download" href="http://dev.mysql.com/downloads/cluster/">http://dev.mysql.com/downloads/cluster/</a>
for newer versions. </p>
<p>Use my <a href="files/install.txt">install script</a> to install
MySQL. You can read the various comments in the script. Please read the
comments before you execute each section in the script. In general, it
will attempt to setup three things:
</p>
<ol>
<li>A MySQL Cluster
</li>
<li>A regular slave
</li>
<li>A MySQL cluster slave
</li>
</ol>
No replication will be setup however. This install script downloads,
compiles, and sets up the basic environment. To execute this script:
<ul>
<li>You must have sudo access. If not, just log in as the root user.
For example: <font color="blue">su -l root</font>
</li>
<li>Download the script.
</li>
<li>mv install.txt install.sh
</li>
<li>bash install.sh # However, I recommend only doing sections at a time. 
I got the script to work all the way through, but this script doesn't allow 
for errors, so it is safer to just do sections at a time. Copy and 
paste sections into a terminal session.
</li>
</ul>
<hr>
<h2><a name="rep"></a>Setting up and Testing Replication to a Slave
and Cluster Slave</h2>
We assume
the MySQL cluster and the slaves are running. Replication is not setup
yet, but it will be. Now we will setup replication where each of the
two MySQL nodes will replicate non-NDB tables
to each other. Also, we will setup replication from the first MySQL
node to a MySQL slave and the 2nd MySQL node to the cluster slave. 
The important thing to note is that the slaves
will replicate all the data from all databases.
<p>NOTE: We only use Row Level Replication. It is possible to do this
with Statement Level Replication, but it gets more complicated. </p>
<p>Look at my <a href="files/slave_setup.txt">slave setup script</a>.
</p>
<hr>
<h2><a name="test"></a>Let's test MySQL</h2>
<pre class="code">./bin/mysql -u root -S instances/mysqlnode1/tmp/mysql.sock -e "create database if not exists ndb"<br>
./bin/mysql -u root -S instances/mysqlslave1/tmp/mysql.sock -e "show databases"
./bin/mysql -u root -S instances/mysqlslave1/tmp/mysql.sock -e "create database if not exists ndb"<br>
./bin/mysql -u root -S instances/mysqlslave1/tmp/mysql.sock -e "create table if not exists ndb.ndb1 (i int) engine=InnoDB;"
./bin/mysql -u root -S instances/mysqlnode1/tmp/mysql.sock -e "create table if not exists ndb.ndb1 (i int) engine=ndb;" 
./bin/mysql -u root -S instances/mysqlnode1/tmp/mysql.sock -e "create table if not exists rep.rep1 (i int) engine=InnoDB;" <br>
./bin/mysql -u root -S instances/mysqlnode1/tmp/mysql.sock -e "insert into ndb.ndb1 values (1);" 
./bin/mysql -u root -S instances/mysqlnode2/tmp/mysql.sock -e "insert into rep.rep1 values (1);"<br>
# These tables should contain one row each. 
./bin/mysql -N -u root -S instances/mysqlnode1/tmp/mysql.sock -e "select * from ndb.ndb1"
./bin/mysql -N -u root -S instances/mysqlnode1/tmp/mysql.sock -e "select * from rep.rep1"
./bin/mysql -N -u root -S instances/mysqlnode2/tmp/mysql.sock -e "select * from ndb.ndb1"
./bin/mysql -N -u root -S instances/mysqlnode2/tmp/mysql.sock -e "select * from rep.rep1"
./bin/mysql -N -u root -S instances/mysqlslave1/tmp/mysql.sock -e "select * from ndb.ndb1"
./bin/mysql -N -u root -S instances/mysqlslave1/tmp/mysql.sock -e "select * from rep.rep1"
./bin/mysql -N -u root -S instances/mysqlcslave1/tmp/mysql.sock -e "select * from ndb.ndb1"
./bin/mysql -N -u root -S instances/mysqlcslave1/tmp/mysql.sock -e "select * from rep.rep1"<br>
# Test replication for the non-replicating database. 
./bin/mysql -u root -S instances/mysqlnode1/tmp/mysql.sock -e "create table if not exists norep.norep1 (i int) engine=InnoDB;"
./bin/mysql -u root -S instances/mysqlnode2/tmp/mysql.sock -e "create table if not exists norep.norep1 (i int) engine=InnoDB;"
./bin/mysql -u root -S instances/mysqlslave1/tmp/mysql.sock -e "create table if not exists norep.norep1 (i int) engine=InnoDB;"
./bin/mysql -u root -S instances/mysqlcslave1/tmp/mysql.sock -e "create table if not exists norep.norep1 (i int) engine=InnoDB;"<br>
./bin/mysql -u root -S instances/mysqlnode1/tmp/mysql.sock -e "insert into norep.norep1 values (1);"
./bin/mysql -u root -S instances/mysqlnode2/tmp/mysql.sock -e "insert into norep.norep1 values (2);"
./bin/mysql -u root -S instances/mysqlslave1/tmp/mysql.sock -e "insert into norep.norep1 values (3);"
./bin/mysql -u root -S instances/mysqlcslave1/tmp/mysql.sock -e "insert into norep.norep1 values (4);"<br>
# These tables should contain one unique value.
./bin/mysql -N -u root -S instances/mysqlnode1/tmp/mysql.sock -e "select * from norep.norep1"
./bin/mysql -N -u root -S instances/mysqlnode2/tmp/mysql.sock -e "select * from norep.norep1"
./bin/mysql -N -u root -S instances/mysqlslave1/tmp/mysql.sock -e "select * from norep.norep1"
./bin/mysql -N -u root -S instances/mysqlcslave1/tmp/mysql.sock -e "select * from norep.norep1"<br>
</pre>
You should see one line of data in both tables on the slave.
<hr>
<h2><a name="sp"></a>Installing Stored procedure on Slave</h2>
<p>
When a MySQLd server using NDB restarts, it sends out an error message.
It is not usually a good idea to restart replication without knowing
what is going on and
checking the logs. However, there may be times when you don't care. For
that case, I have created a stored procedure using an event to kick off
replication when a known
error occurs. This stored procedure only works for the first 5 days. If
you wish, you can modify it for a longer period of time. </p>
<p>Let's kill replication, install the stored procedure, and then see
if it fixes replication. </p>
<ol>
<li>Download this file: <a href="files/stored_procedure_rep.sp">files/stored_procedure_rep.sp</a>
</li>
<li>
<pre>if [ -e "instances/mysqlnode1/tmp/mysqld.pid" ]; then
 k=`cat instances/mysqlnode1/tmp/mysqld.pid`
 echo "Killing $k"
 kill $k
fi
if [ -e "instances/mysqlnode2/tmp/mysqld.pid" ]; then
 k=`cat instances/mysqlnode2/tmp/mysqld.pid`
 echo "Killing $k"
 kill $k
fi

sleep 2
if [ -e "instances/mysqlnode1/tmp/mysqld.pid" ]; then
 echo "Mysql node 1 still running."
else
 echo "starting node 1 mysql"
 sudo -u mysql nohup ./libexec/mysqld --defaults-file=etc/my.cnf_node1 &amp;
fi
if [ -e "instances/mysqlnode2/tmp/mysqld.pid" ]; then
 echo "Mysql node 2 still running."
else
 echo "starting node 2 mysql"
 sudo -u mysql nohup ./libexec/mysqld --defaults-file=etc/my.cnf_node2 &amp;
fi

</pre>
</li>
<li>Add the following to the config files if it is not already
done: "event_scheduler=ON". The config files in this article already
have that setting. If you had to add this to your config, restart the MySQLd servers.</li>
<li>Check replication. One of the two fields should be 'No'.
<pre>./bin/mysql -u root -S instances/mysqlnode1/tmp/mysql.sock -e "show slave status\G" | grep -i running
./bin/mysql -u root -S instances/mysqlnode2/tmp/mysql.sock -e "show slave status\G" | grep -i running
./bin/mysql -u root -S instances/mysqlslave1/tmp/mysql.sock -e "show slave status\G" | grep -i running
./bin/mysql -u root -S instances/mysqlcslave1/tmp/mysql.sock -e "show slave status\G" | grep -i running
</pre>
</li>
<li>Install the stored procedure below on the slave.
<pre>./bin/mysql -u root -S instances/mysqlnode1/tmp/mysql.sock -e "source stored_procedure_rep.sp" mysql
./bin/mysql -u root -S instances/mysqlnode2/tmp/mysql.sock -e "source stored_procedure_rep.sp" mysql
./bin/mysql -u root -S instances/mysqlslave1/tmp/mysql.sock -e "source stored_procedure_rep.sp" mysql
./bin/mysql -u root -S instances/mysqlcslave1/tmp/mysql.sock -e "source stored_procedure_rep.sp" mysql
</pre>
</li>
<li>Wait 1 minute. Slave_IO_Running and Slave_SQL_Running should be
'Yes'.
<pre>./bin/mysql -u root -S instances/mysqlnode1/tmp/mysql.sock -e "show slave status\G"
./bin/mysql -u root -S instances/mysqlnode2/tmp/mysql.sock -e "show slave status\G"
./bin/mysql -u root -S instances/mysqlslave1/tmp/mysql.sock -e "show slave status\G"
./bin/mysql -u root -S instances/mysqlcslave1/tmp/mysql.sock -e "show slave status\G"<br>
# or just

./bin/mysql -u root -S instances/mysqlnode1/tmp/mysql.sock -e "show slave status\G" | grep -i running
./bin/mysql -u root -S instances/mysqlnode2/tmp/mysql.sock -e "show slave status\G" | grep -i running
./bin/mysql -u root -S instances/mysqlslave1/tmp/mysql.sock -e "show slave status\G" | grep -i running
./bin/mysql -u root -S instances/mysqlcslave1/tmp/mysql.sock -e "show slave status\G" | grep -i running<br>
</pre>
</li>
<li>"Show slave status" should have both the io_thread and sql_thread
as 'Yes' after the stored procedure kicks in.
</li>
</ol>
<hr>
<h2><a name="con"></a>Conclusion and Future Topics</h2>
Well, there's nothing much to conclude except that you can setup a MySQL
Cluster on a single box. It works for Ubuntu and CentOS pretty well.
<p>Here are some future topics:
</p>
<ol>
<li>Stress test MySQL Cluster on a single box and get it to break.
Hint: The config files in this article were made so that I could load
real production data on a server at work without having the cluster
kick out the data nodes. </li>
<li>Break MySQL Cluster by pounding it to death or filling up
diskspace or filling up the index in memory and see what happens. </li>
<li>Split the configurations out to two servers. </li>
<li>Setup Statement Level Replication. </li>
<li>Perform backups via cluster or slave. </li>
<li>Managing the cluster and Nagios alarms for the cluster to detect
when things go bad. </li>
<li>Adding and dropping nodes manually.
</li>
<li>Creating Ubuntu and CentOS packages. </li>
<li>Testing my SSD drive.
</li>
</ol>

<hr>
<h2><a name="ssd"></a>Some SSD Preliminary Testing</h2>
I ran a quick test on the performance of my SSD drive compared to the brand new SATA drive that I bought. 
However, it is not a very good test because my computer is 4.5 years old. 
The important thing to keep in mind is that SSD drives perform much better with random writes and reads.
They are somewhat better for sequential writes and reads. For a database server, random writes
and reads are the most important. When you look at the tables below, you might except the sequential 
copying of cds should go about as fast as sequential inserts into MySQL Cluster. However, even 
sequential inserts, are not exactly sequential in all respects. As I expected, straight inserts went 
a lot faster on the SSD drive and looked closer to random write speed improvements.  
<p>
I loaded data onto both the SSD and the SATA drives I have. I have separate MySQL Cluster 
installations on each hard drive. 
My computer is from late 2004, so it probably only a SATA I bus. So this is a really bad test for 
testing real performance, but I just wanted to get a rough idea of what I am dealing with. Both the 
SATA drive and the SSD drive were brand new. I was using an SSD Vertex 60 gig drive. I loaded a 200 MB 
file onto the system, but, there were 4 MySQL instances running. The two data nodes for the cluster, a 
slave, and a cluster slave. In addition, the binlogs would have a copy of all the data for the MySQLd 
instances. Thus, there are 8 copies of the data (4 in the databases, 4 in logs). I expect on a system 
with just one MySQL instance it would run a lot faster. 
<p>
For cdrom copying times of 700 megs, look at this table. The SSD drives appears to be about 
66% faster. However, when you compare this to the next table, SSD shows to be even better (as expected).
<table SUMMARY="Results Summary" border=1>
<tr><td>Cd copy count<th>SATA seconds <th>SSD seconds</tr>
<tr><td>1<td>28<td>20</tr>
<tr><td>2<td>29<td>19</tr>
<tr><td>3<td>34<td>20</tr>
<tr><td>4<td>32<td>19</tr>
<tr><td>5<td>30<td>19</tr>
<tr><td>6<td>32<td>20</tr>
<tr><td>7<td>32<td>18</tr>
<tr><td>8<td>32<td>20</tr>
</table>
<p>

We can see that the MySQL Cluster is running 2 to 5 times faster on the SSD drive. This is not surprising if the latency on the
SSD drive is better. The inserts below were at 1000 rows at a time. The python script has the detailed schema information. I compared 3 different points in the log files
for the inserts. I compared the recent time for 1000 rows being inserted and the total time up to that point. The loading stopped at 1 million rows. 
<table SUMMARY="Detailed Results" border=1>
<tr><th>Rows<th>SATA Drive<th>SSD Drive<th>Total time  Ratio<th>1000 time ratio</tr>
<tr><td>122,000 rows 
<td><pre>Query OK, 1000 rows affected (0.13 sec)
Records: 1000  Duplicates: 0  Warnings: 0

+-------------------------+--------+
| seconds_diff            | 122000 |
+-------------------------+--------+
|                      31 | 122000 |
+-------------------------+--------+
1 row in set (0.00 sec)
</pre>
<td><pre>Query OK, 1000 rows affected (0.08 sec)
Records: 1000  Duplicates: 0  Warnings: 0

+-------------------------+--------+
| seconds_diff            | 122000 |
+-------------------------+--------+
|                      13 | 122000 |
+-------------------------+--------+
1 row in set (0.00 sec)
</pre>
<td>2.3<td>1.6</tr>

<tr><td>715,000 rows<td><pre>
+-------------------------+--------+
| seconds_total           | 715000 |
+-------------------------+--------+
|                    1819 | 715000 |
+-------------------------+--------+
1 row in set (0.00 sec)

Query OK, 1000 rows affected (4.96 sec)
Records: 1000  Duplicates: 0  Warnings: 0
</pre></td>
<td><pre>
+-------------------------+--------+
| seconds_total           | 715000 |
+-------------------------+--------+
|                     353 | 715000 |
+-------------------------+--------+
1 row in set (0.00 sec)

Query OK, 1000 rows affected (1.18 sec)
Records: 1000  Duplicates: 0  Warnings: 0
</pre><td>5.1<td>4.2
</tr>


<tr><td>1 million rows 
<td><pre>Query OK, 1000 rows affected (4.46 sec)
Records: 1000  Duplicates: 0  Warnings: 0

+-------------------------+---------+
| seconds_diff            | 1000000 |
+-------------------------+---------+
|                    3188 | 1000000 |
+-------------------------+---------+
1 row in set (0.00 sec)
</pre>
<td><pre>Query OK, 1000 rows affected (1.40 sec)
Records: 1000  Duplicates: 0  Warnings: 0

+-------------------------+---------+
| seconds_diff            | 1000000 |
+-------------------------+---------+
|                     743 | 1000000 |
+-------------------------+---------+
1 row in set (0.00 sec)
</pre>
<td>4.2<td>3.1
</tr>

</table>

To reproduce the results for yourself, install MySQL Cluster twice. Once on a normal drive and once on an SSD drive. 
<p>
Execute the following in the MySQL cluster for the SSD drive and then later for the normal drive and then compare the times. 
Also, download my 
<a href="files/Insert_200_megs_random.py">insert python script</a>. I wrote it up very quick. It isn't that elegant. 
<pre>
Insert_200_megs_random.py &gt; insert1.sql
bin/mysql -u root  -S  instances/mysqlnode1/tmp/mysql.sock
</pre>

Inside the mysql client program
<pre>
tee insert1.log
source insert1.log

</pre>

Here's the output of my dmesg, if this helps.
<pre>
[    1.338264] sata_promise 0000:00:08.0: version 2.12
[    1.338294] sata_promise 0000:00:08.0: PCI INT A -&gt; GSI 18 (level, low) -&gt; IRQ 18
[    1.352185] scsi0 : sata_promise
[    1.352328] scsi1 : sata_promise
[    1.352388] scsi2 : sata_promise
[    1.352430] ata1: SATA max UDMA/133 mmio m4096@0xf7a00000 ata 0xf7a00200 irq 18
[    1.352434] ata2: SATA max UDMA/133 mmio m4096@0xf7a00000 ata 0xf7a00280 irq 18
[    1.352436] ata3: PATA max UDMA/133 mmio m4096@0xf7a00000 ata 0xf7a00300 irq 18
[    1.672036] ata1: SATA link up 1.5 Gbps (SStatus 113 SControl 300)
[    1.707733] ata1.00: ATA-8: ST31500341AS, CC1H, max UDMA/133
[    1.707736] ata1.00: 2930277168 sectors, multi 0: LBA48 NCQ (depth 0/32)
[    1.763738] ata1.00: configured for UDMA/133
[    2.080030] ata2: SATA link up 1.5 Gbps (SStatus 113 SControl 300)
[    2.088384] ata2.00: ATA-7: OCZ-VERTEX 1275, 00.P97, max UDMA/133
[    2.088387] ata2.00: 125045424 sectors, multi 16: LBA48 NCQ (depth 0/32)
[    2.096398] ata2.00: configured for UDMA/133
[    2.252082] isa bounce pool size: 16 pages
[    2.252207] scsi 0:0:0:0: Direct-Access     ATA      ST31500341AS     CC1H PQ: 0 ANSI: 5
[    2.252323] sd 0:0:0:0: [sda] 2930277168 512-byte hardware sectors: (1.50 TB/1.36 TiB)
[    2.252342] sd 0:0:0:0: [sda] Write Protect is off
[    2.252345] sd 0:0:0:0: [sda] Mode Sense: 00 3a 00 00
[    2.252370] sd 0:0:0:0: [sda] Write cache: enabled, read cache: enabled, doesn't support DPO or FUA
[    2.252449] sd 0:0:0:0: [sda] 2930277168 512-byte hardware sectors: (1.50 TB/1.36 TiB)
[    2.252462] sd 0:0:0:0: [sda] Write Protect is off
[    2.252464] sd 0:0:0:0: [sda] Mode Sense: 00 3a 00 00
[    2.252487] sd 0:0:0:0: [sda] Write cache: enabled, read cache: enabled, doesn't support DPO or FUA
[    2.252492]  sda: sda1 sda2 sda4
[    2.282713] sd 0:0:0:0: [sda] Attached SCSI disk
[    2.282781] sd 0:0:0:0: Attached scsi generic sg0 type 0
[    2.282842] scsi 1:0:0:0: Direct-Access     ATA      OCZ-VERTEX 1275  00.P PQ: 0 ANSI: 5
[    2.282924] sd 1:0:0:0: [sdb] 125045424 512-byte hardware sectors: (64.0 GB/59.6 GiB)
[    2.282938] sd 1:0:0:0: [sdb] Write Protect is off
[    2.282941] sd 1:0:0:0: [sdb] Mode Sense: 00 3a 00 00
[    2.282963] sd 1:0:0:0: [sdb] Write cache: enabled, read cache: enabled, doesn't support DPO or FUA
[    2.283011] sd 1:0:0:0: [sdb] 125045424 512-byte hardware sectors: (64.0 GB/59.6 GiB)
[    2.283024] sd 1:0:0:0: [sdb] Write Protect is off
[    2.283026] sd 1:0:0:0: [sdb] Mode Sense: 00 3a 00 00
[    2.283049] sd 1:0:0:0: [sdb] Write cache: enabled, read cache: enabled, doesn't support DPO or FUA

</pre>

Some proc info
<pre>
gt;more /proc/scsi/sg/device_strs
ATA             ST31500341AS            CC1H
ATA             OCZ-VERTEX 1275         00.P
DVDRW           IDE1008                 0055
</pre>

For more info on SSD:
<ul>
<li><a href="http://www.anandtech.com/storage/showdoc.aspx?i=3531&amp;p=25">http://www.anandtech.com/storage/showdoc.aspx?i=3531&amp;p=25</a>
</li>
<li><a href="http://www.anandtech.com/storage/showdoc.aspx?i=3531&amp;p=1">http://www.anandtech.com/storage/showdoc.aspx?i=3531&amp;p=1</a>
</li>
<li><a href="http://www.anandtech.com/storage/showdoc.aspx?i=3535">http://www.anandtech.com/storage/showdoc.aspx?i=3535</a>
</li>
<li><a href="http://www.anandtech.com/cpuchipsets/intel/showdoc.aspx?i=3403&amp;p=11">http://www.anandtech.com/cpuchipsets/intel/showdoc.aspx?i=3403&amp;p=11</a>
</li>
<li><a href="http://www.anandtech.com/storage/showdoc.aspx?i=3531&amp;p=25">http://www.anandtech.com/storage/showdoc.aspx?i=3531&amp;p=25</a>
</li>
</ul>
<p>
As a side note, SLC SSD drives last 10 times longer for writes comapared to the MLC SSD drives, from what I understand. 
Thus, the Intel x25-e is far more important than the Intel x25-m for database servers. You want the drives to last as long as possible
and have the best random write performance. On one of my contracting jobs, because I showed them how the Vortex behaved on my home
computer, I will get to test an Intel x25-e at their place. That's the second time when I invested in my computer at home it helped me 
in my career. The first time was getting an AMD 64 bit system before most companies had it and using it at home with Linux and MySQL. 
The ex complained it was a waste of money, but it was a hell of an impressive thing to say at the time during interviews that I had
64 bit Linux and MySQL running at home, and it proved to be true. If you get a good raise because you show initiative when investing money into
your home equipment to prove something, it pays for itself. 
</p>


<br clear="all" />

<script type='text/javascript'>
digg_url = 'http://linuxgazette.net/168/nielsen.html';
digg_title = 'Setting up a MySQL Cluster for your Linux desktop';
digg_bodytext = '<p> MySQL Cluster has come a long way in the 4 years since I experimented with it. Compared to when I first got the cluster working on my home computer, I didn\'t have to change much get the latest version up and running. </p> ';
digg_topic = 'linux_unix';
</script>
<script src="http://digg.com/tools/diggthis.js" type="text/javascript"></script>

</p>

<p class="talkback">
Talkback: <a
href="mailto:tag@lists.linuxgazette.net?subject=Talkback:168/nielsen.html">Discuss this article with The Answer Gang</a>
</p>

<!-- *** BEGIN author bio *** -->
	<!-- *** BEGIN bio *** -->
<hr>
<P>
<img ALIGN="LEFT" ALT="Bio picture" SRC="../gx/2002/note.png" class="bio">
<em>
Mark leads the Ubuntu California Team. You can reach him at
ubuntu.ca.team@gmail.com .
</em>
<br CLEAR="all">
<!-- *** END bio *** -->

<!-- *** END author bio *** -->

<div id="articlefooter">


<p>
Copyright &copy; 2009, <a href="../authors/nielsen.html">Mark Nielsen</a>. Released under the
<a href="http://linuxgazette.net/copying.html">Open Publication License</a>
unless otherwise noted in the body of the article. Linux Gazette is not
produced, sponsored, or endorsed by its prior host, SSC, Inc.
</p>


<p>
Published in Issue 168 of Linux Gazette, November 2009
</p>

</div>
</div>


<div class="content lgcontent">

<a name="silva"></a>
<h1>A 'revisited' guide to GNU Screen</h1>
<p id="by"><b>By <a href="../authors/silva.html">Anderson Silva</a> and <a href="../authors/milner.html">Steve 'Ashcrow' Milner</a></b></p>

</b>
</p>

<p>
<p>
Remember how tabbed browsing revolutionized the web experience? GNU Screen
can do the same for your experience in the command line. Screen allows
you to manage several interactive shell instances within the same "window".
By using different keyboard shortcuts, you can shuffle through the shell
instances, access any of them directly, create new ones, kill old ones, and
attach and detach existing ones.
</p>

<p>
Instead of opening up several terminal instances on your desktop or
using those ugly GNOME/KDE-based tabs, Screen can do it better
and simpler.
</p>

<p>
Not only that, with Screen you can share sessions with others
and detach/attach terminal sessions. It is a great tool for people who have
to share working environments between work and home.
</p>

<p>
By adding a status bar to your screen environment, you are able to
name your shell instances on the fly or via a configuration file called
.screenrc that can be created in the user's home directory.	
</p>

<h3>Installation</h3>
<p>
Installing screen on a Fedora system is quite easy with yum,
assuming you have root access.
</p>

<ol>
<li>
<p>
Login as root:
</p>
<pre class="code">su - # enter root password</pre>
</li>
<li>
<p>
Use yum to install it:
</p>
<pre class="code">yum install screen</pre>
</li>
</ol>
<p>
On Debian based distributions like Ubuntu:
</p>
<ol>
<li>
<p>
As root:
</p>
<pre class="code">apt-get install screen</pre>
</li>
</ol>

<p>
Enter your password. After a few minutes (depending on your network
connection), Screen will be installed. But before you start playing around
with it, let's look at how to do some basic configuration.	
</p>

<h3>Customizing the configuration file</h3>
<p>
Screen keeps its configuration file in the same vein that many
applications do: in a dot file in your user's home directory. This file
is aptly named .screenrc. In my experience, most people use ~/.screenrc to
do two things:
</p>

<ul>
<li>
<em>Make a hardstatus line.</em> This is basically a line at the bottom of the
screen that lists your current terminal and all opened ones. It can also
display the system clock and the hostname.
</li>
<li>
<em>Default screens on startup.</em> It's quite nice to have your IRC connection,
mail client, and default SSH connections auto-start for you!
</li>
</ul>
<p>
The lines below are numbered for reference. Your config file should
not have numbered lines.
</p>

<pre class="code">
1 hardstatus alwayslastline
2 hardstatus string '%{= kG}[ %{G}%H %{g}][%= %{=kw}%?%-Lw%?%{r}(%{W}%n*%f%t%?(%u)%?%{r})%{w}%?%+Lw%?%?%= %{g}][%{B}%Y-%m-%d %{W}%c %{g}]'
3
4 # Default screens
5 screen -t shell1 0
6 screen -t shell2 1
7 screen -t server 2 ssh me@myserver
</pre>
<p>
On lines 1 and 2, you are setting the hardstatus. Line 1 makes the
hardstatus always show up as the last line. Line 2 is what will be shown in
the hardstatus line. In this case you will see something like this at the
bottom:
</p>

<p>
<img src="misc/silva/file1.jpg" alt="Screenshot of GNU Screen.">
</p>

<p>
As you change screens, you will see the parentheses move around the
active screen.	
</p>

<p>
	Line 4 is a comment, as it starts with #. Lines 5-7 are all screen
statements in the following format:
</p>

<pre class="code">
screen -t NameOfScreen ScreenNumber ShellCommand</pre>

<h3>Shortcuts</h3>
<p>
The following are some of the most commonly used shortcuts that let
you navigate through your screen environment. Note that unless modified by
your .screenrc, by default every screen shortcut is preceded by Ctrl+a.
Note also that these shortcuts are case-sensitive.
</p>

<ul>
<li>
0 through 9 â Switches between windows
</li>
<li>
Ctrl+n â Switches to the next available window
</li>
<li>
Backspace â Switches to the previous available window
</li>
<li>
Ctrl+a â Switches back to the last window you were on
</li>
<li>
A â Changes window session name
</li>
<li>
K â Kills a window session
</li>
<li>
c â Creates a new window
</li>
<li>
[ - Then use arrows to scroll up and down terminal
</li>
<li>
" - Displays a lists of all opened tabs allowing navigation with your arrow keys.
</li>
</ul>

<p>
	You can learn more about shortcuts in Screen's man pages. In your
terminal, run:
</p>

<pre class="code">man screen</pre>

<h3>Sharing a session with others</h3>

<p>
Another great application of Screen is to allow other people to
login to your station and to watch the work you are doing. It is a great
way to teach someone how to do things in the shell.
</p>

<p>
<b>Note:</b> <em>Screen has to be SUID if you want to share a terminal between
two users. SUID allows an executable to be run with the privileges of
the owner of that file, instead of with the user's own privileges. There
are some security concerns when doing this, so use this tip at your own
discretion.</em>
</p>

<h3>Setup to allow screen to be shared</h3>

<p>
First, as root:
</p>

<pre class="code">
chmod u+s /usr/bin/screen
chmod 755 /var/run/screen
</pre>

<p>
Log out of root, and run Screen as the user who is going to share the session:
</p>

<pre class="code">screen</pre>

<p>
Under your new screen session:
</p>

<ol>
<li>

<p>
Press Ctrl+a, then type ':multiuser on' and press Enter.
</p>

</li>
<li>

<p>
Press Ctrl+a, then type ':acladd $username'
</p>

</li>
</ol>

<p>
Where $username is the username of the person who will connect to your
screen session.
</p>

<h3>Connecting to the shared screen</h3>

<p>
Now that a screen session is being shared by following the previous steps,
let's attach ourselves to the session and watch it by connecting to the
machine via ssh and entering the following command:
</p>

<pre class="code">screen -x $username/</pre>

<p>
Where $username is the username of the person who is sharing the screen
session, and yes, you do need slash (/) at the end of the command.
</p>

<p>
And now both the users (from the host and guest) will be sharing a
screen session and can run commands on the terminal.
</p>

<h3>Working from multiple locations</h3>
<p>
Let's say you have a screen session open at work with X number of
windows on it. Within those screens you may be running an IRC client, an
SSH connection to the web server, and your favorite text-based email
client. It's 5 p.m. and you have to go home, but you still have work left
to do.
</p>

<p>
Without Screen you would probably go home, VPN into your company's
network, and fire up all the shells you need to keep working from home.
With Screen, life gets a little easier.
</p>

<p>
You can simply SSH into your workstation at work and list your
available screen sessions with the command:
</p>

<pre class="code">screen -ls</pre>

<p>
And connect to the sessions you were running at work with the
command:
</p>

<pre class="code">screen -x screen_session_name</pre>

<p>
This way screen will let you pick things up exactly from where you
left off.
</p>

<p>
Once you get used to the shortcuts in GNU Screen, not only will your
desktop become more organized (due to the lower number of open windows),
but your efficiency as a developer or system administrator will increase
not only at work but at your home office as well.
</p>



<br clear="all" />

<script type='text/javascript'>
digg_url = 'http://linuxgazette.net/168/silva.html';
digg_title = 'A \'revisited\' guide to GNU Screen';
digg_bodytext = '<p> Remember how tabbed browsing revolutionized the web experience? GNU Screen can do the same for your experience in the command line. Screen allows you to manage several interactive shell instances within the same "window". By using different keyboard shortcuts, you can shuffle through the shell instances, access any of them directly, create new ones, kill old ones, and attach and detach existing ones. </p> ';
digg_topic = 'linux_unix';
</script>
<script src="http://digg.com/tools/diggthis.js" type="text/javascript"></script>

</p>

<p class="talkback">
Talkback: <a
href="mailto:tag@lists.linuxgazette.net?subject=Talkback:168/silva.html">Discuss this article with The Answer Gang</a>
</p>

<!-- *** BEGIN author bio *** -->
	<hr>
<p>
<img align="left" alt="[BIO]" src="../gx/authors/silva.jpg" class="bio">
</p>

<em>
<p>
Anderson Silva works as an IT Release Engineer at Red Hat, Inc. He
holds a BS in Computer Science from Liberty University, a MS in
Information Systems from the University of Maine. He is a Red Hat
Certified Engineer working towards becoming a Red Hat Certified
Architect and has authored several Linux based articles for
publications like: Linux Gazette, Revista do Linux, and Red Hat
Magazine. Anderson has been married to his High School sweetheart,
Joanna (who helps him edit his articles before submission), for 11
years, and has 3 kids. When he is not working or writing, he enjoys
photography, spending time with his family,  road cycling, watching
Formula 1 and Indycar races, and taking his boys karting,
</p>

</em>

<br clear="all">


	<hr>
<p>
<img align="left" alt="[BIO]" src="../gx/2002/note.png" class="bio">
</p>

<em>
<p>
Steve 'Ashcrow' Milner works as a Security Analyst at Red Hat, Inc. He
 is a Red Hat Certified Engineer and is certified on ITIL Foundations.
 Steve has two dogs, Anubis and Emma-Lee who guard his house. In his
 spare time Steve enjoys robot watching, writing open code, caffeine,
 climbing downed trees and reading comic books.
</p>



</em>

<br clear="all">


<!-- *** END author bio *** -->

<div id="articlefooter">


<p>
Copyright &copy; 2009, <a href="../authors/silva.html">Anderson Silva</a> and <a href="../authors/milner.html">Steve 'Ashcrow' Milner</a>. Released under the
<a href="http://linuxgazette.net/copying.html">Open Publication License</a>
unless otherwise noted in the body of the article. Linux Gazette is not
produced, sponsored, or endorsed by its prior host, SSC, Inc.
</p>


<p>
Published in Issue 168 of Linux Gazette, November 2009
</p>

</div>
</div>


<div class="content lgcontent">

<a name="collinge"></a>
<h1>HelpDex</h1>
<p id="by"><b>By <a href="../authors/collinge.html">Shane Collinge</a></b></p>

</b>
</p>

<p>

<p>
<em>These images are scaled down to minimize horizontal scrolling.</em>
</p>

<a href="http://linuxgazette.net/124/misc/nottag/flash.html"><b>Flash problems?</b></a>
<br>

<div class="cartoon">

<object>
<embed src="misc/collinge/092fries.swf" bgcolor="#ffffff" width="600" />
</object>

<a href="misc/collinge/092fries.swf"><p>Click here to see the full-sized image</p></a>

</div>

<p> All HelpDex cartoons are at Shane's web site,
<a href="http://www.shanecollinge.com/">www.shanecollinge.com</a>.

<script src="http://www.google-analytics.com/urchin.js"
type="text/javascript">
</script>
<script type="text/javascript">
_uacct = "UA-1204316-1";
urchinTracker();
</script>


</p>

<p class="talkback">
Talkback: <a
href="mailto:tag@lists.linuxgazette.net?subject=Talkback:168/collinge.html">Discuss this article with The Answer Gang</a>
</p>

<!-- *** BEGIN author bio *** -->
	<!-- *** BEGIN bio *** -->
<hr>
<P>
<img ALIGN="LEFT" ALT="Bio picture" SRC="../gx/2002/note.png" class="bio">
<em>
Part computer programmer, part cartoonist, part Mars Bar. At night, he runs
around in his brightly-coloured underwear fighting criminals. During the
day... well, he just runs around in his brightly-coloured underwear. He
eats when he's hungry and sleeps when he's sleepy.
</em>
<br CLEAR="all">
<!-- *** END bio *** -->

<!-- *** END author bio *** -->

<div id="articlefooter">


<p>
Copyright &copy; 2009, <a href="../authors/collinge.html">Shane Collinge</a>. Released under the
<a href="http://linuxgazette.net/copying.html">Open Publication License</a>
unless otherwise noted in the body of the article. Linux Gazette is not
produced, sponsored, or endorsed by its prior host, SSC, Inc.
</p>


<p>
Published in Issue 168 of Linux Gazette, November 2009
</p>

</div>
</div>


<div class="content lgcontent">

<a name="ecol"></a>
<h1>Ecol</h1>
<p id="by"><b>By <a href="../authors/malonda.html">Javier Malonda</a></b></p>

</b>
</p>

<p>
The Ecol comic strip is written for <a
href="http://escomposlinux.org">escomposlinux.org</a> (ECOL), the web site that
supports es.comp.os.linux, the Spanish USENET newsgroup for Linux.  The
strips are drawn in Spanish and then translated to English by the author.
<p>
<em>These images are scaled down to minimize horizontal scrolling.</em>
</p>


<div class="cartoon">
<a href="misc/ecol/tiraecol_en-14.png">
<img alt="[cartoon]" src="misc/ecol/tiraecol_en-14.png"><p>Click here to see the full-sized image</a>
</div>

All Ecol cartoons are at
<a href="http://tira.escomposlinux.org/">tira.escomposlinux.org</a> (Spanish),
<a href="http://comic.escomposlinux.org/">comic.escomposlinux.org</a> (English) 
and
<a href="http://tira.puntbarra.com/">http://tira.puntbarra.com/</a> (Catalan).
The Catalan version is translated by the people who run the site; only a few
episodes are currently available.

<p> <small>These cartoons are copyright Javier Malonda.  They may be copied,
linked or distributed by any means.  However, you may not distribute
modifications.  If you link to a cartoon, please <a
href="mailto:jmr@escomposlinux.org">notify</a> Javier, who would appreciate
hearing from you.
</small>

<script src="http://www.google-analytics.com/urchin.js"
type="text/javascript">
</script>
<script type="text/javascript">
_uacct = "UA-1204316-1";
urchinTracker();
</script>



</p>

<p class="talkback">
Talkback: <a
href="mailto:tag@lists.linuxgazette.net?subject=Talkback:168/ecol.html">Discuss this article with The Answer Gang</a>
</p>

<!-- *** BEGIN author bio *** -->
	<!-- *** BEGIN bio *** -->
<hr>
<!-- P>
<img ALIGN="LEFT" ALT="Bio picture" SRC="../gx/2002/note.png" class="bio">
<em>
</em>
<br CLEAR="all" -->
<!-- *** END bio *** -->

<!-- *** END author bio *** -->

<div id="articlefooter">


<p>
Copyright &copy; 2009, <a href="../authors/malonda.html">Javier Malonda</a>. Released under the
<a href="http://linuxgazette.net/copying.html">Open Publication License</a>
unless otherwise noted in the body of the article. Linux Gazette is not
produced, sponsored, or endorsed by its prior host, SSC, Inc.
</p>


<p>
Published in Issue 168 of Linux Gazette, November 2009
</p>

</div>
</div>


<div class="content lgcontent">

<a name="xkcd"></a>
<h1>XKCD</h1>
<p id="by"><b>By <a href="../authors/munroe.html">Randall Munroe</a></b></p>

</b>
</p>

<p>

<p>

<div class="cartoon1">
<a href="misc/xkcd/command_line_fu.png">
<img alt="[cartoon]" title="When designing an interface, imagine that your program is all that stands between the user and hot, sweaty, tangled-bedsheets-fingertips-digging-into-the-back sex.
" src="misc/xkcd/command_line_fu.png"><p>Click here to see the full-sized image</a>
</div>

More XKCD cartoons can be found
<a href="http://xkcd.com">here</a>.


<script src="http://www.google-analytics.com/urchin.js"
type="text/javascript">
</script>
<script type="text/javascript">
_uacct = "UA-1204316-1";
urchinTracker();
</script>



</p>

<p class="talkback">
Talkback: <a
href="mailto:tag@lists.linuxgazette.net?subject=Talkback:168/xkcd.html">Discuss this article with The Answer Gang</a>
</p>

<!-- *** BEGIN author bio *** -->
	<hr>
<p>
<img align="left" alt="[BIO]" src="../gx/2002/note.png" class="bio">
</p>

<em>
<p>
I'm just this guy, you know? I'm a CNU graduate with a degree in
 physics. Before starting xkcd, I worked on robots at NASA's Langley
 Research Center in Virginia. As of June 2007 I live in Massachusetts. In
 my spare time I climb things, open strange doors, and go to goth clubs
 dressed as a frat guy so I can stand around and look terribly
 uncomfortable. At frat parties I do the same thing, but the other way
 around.
</p>
</em>

<br clear="all">


<!-- *** END author bio *** -->

<div id="articlefooter">


<p>
Copyright &copy; 2009, <a href="../authors/munroe.html">Randall Munroe</a>. Released under the
<a href="http://linuxgazette.net/copying.html">Open Publication License</a>
unless otherwise noted in the body of the article. Linux Gazette is not
produced, sponsored, or endorsed by its prior host, SSC, Inc.
</p>


<p>
Published in Issue 168 of Linux Gazette, November 2009
</p>

</div>
</div>


<div class="content lgcontent">

<a name="doomed"></a>
<h1>Doomed to Obscurity</h1>
<p id="by"><b>By <a href="../authors/trbovich.html">Pete Trbovich</a></b></p>

</b>
</p>

<p>

<p>
<em>These images are scaled down to minimize horizontal scrolling.</em>
</p>

<div class="cartoon">

<p>
<a href="misc/doomed/0000154.jpg">
<img src="misc/doomed/0000154.jpg" bgcolor="#ffffff" width="600" border="none" />
<br /> Click here to see the full-sized image
</a>
</p>

</div>
<div class="cartoon">

<p>
<a href="misc/doomed/0000155.jpg">
<img src="misc/doomed/0000155.jpg" bgcolor="#ffffff" width="600" border="none" />
<br /> Click here to see the full-sized image
</a>
</p>

</div>
<div class="cartoon">

<p>
<a href="misc/doomed/0000153.jpg">
<img src="misc/doomed/0000153.jpg" bgcolor="#ffffff" width="600" border="none" />
<br /> Click here to see the full-sized image
</a>
</p>

</div>
<div class="cartoon">

<p>
<a href="misc/doomed/0000152.jpg">
<img src="misc/doomed/0000152.jpg" bgcolor="#ffffff" width="600" border="none" />
<br /> Click here to see the full-sized image
</a>
</p>

</div>

<p> All "Doomed to Obscurity" cartoons are at Pete Trbovich's site,
<a
href="http://penguinpetes.com/Doomed_to_Obscurity/">http://penguinpetes.com/Doomed_to_Obscurity/</a>.

<script src="http://www.google-analytics.com/urchin.js"
type="text/javascript">
</script>
<script type="text/javascript">
_uacct = "UA-1204316-1";
urchinTracker();
</script>



</p>

<p class="talkback">
Talkback: <a
href="mailto:tag@lists.linuxgazette.net?subject=Talkback:168/doomed.html">Discuss this article with The Answer Gang</a>
</p>

<!-- *** BEGIN author bio *** -->
	<hr>
<p>
<img align="left" alt="[BIO]" src="../gx/2002/note.png" class="bio">
</p>

<em>
<p>
Born September 22, 1969, in Gardena, California, "Penguin" Pete Trbovich
 today resides in Iowa with his wife and children. Having worked various
 jobs in engineering-related fields, he has since "retired" from
 corporate life to start his second career. Currently he works as a
 freelance writer, graphics artist, and coder over the Internet. He
 describes this work as, "I sit at home and type, and checks mysteriously
 arrive in the mail."
</p>

<p>
He discovered Linux in 1998 - his first distro was Red Hat 5.0 - and has
 had very little time for other operating systems since. Starting out
 with his freelance business, he toyed with other blogs and websites
 until finally getting his own domain penguinpetes.com started in March
 of 2006, with a blog whose first post stated his motto: "If it isn't fun
 for me to write, it won't be fun to read."
</p>

<p>
The webcomic <em>Doomed to Obscurity</em> was launched New Year's Day,
 2009, as a "New Year's surprise". He has since rigorously stuck to a
 posting schedule of "every odd-numbered calendar day", which allows him
 to keep a steady pace without tiring. The tagline for the webcomic
 states that it "gives the geek culture just what it deserves." But is it
 skewering everybody but the geek culture, or lampooning geek culture
 itself, or doing both by turns?
</p>



</em>

<br clear="all">


<!-- *** END author bio *** -->

<div id="articlefooter">


<p>
Copyright &copy; 2009, <a href="../authors/trbovich.html">Pete Trbovich</a>. Released under the
<a href="http://linuxgazette.net/copying.html">Open Publication License</a>
unless otherwise noted in the body of the article. Linux Gazette is not
produced, sponsored, or endorsed by its prior host, SSC, Inc.
</p>


<p>
Published in Issue 168 of Linux Gazette, November 2009
</p>

</div>
</div>


<div class="content lgcontent">

<a name="lg_launderette"></a>
<h1>The Linux Launderette</h1>

</b>
</p>

<p>

<!-- Thread anchor: From the Department of Pedantry --><a name='from_the_department_of_pedantry'></a>
<h3>From the Department of Pedantry</h3>
<p>
<b><p>
Ren&eacute; Pfeiffer [lynx at luchs.at]

</p>
</b><br />
<b>Tue, 13 Oct 2009 23:41:06 +0200</b>
</p>

<p>
On Sep 25, 2009 at 1317 -0700, Rick Moen appeared and said:
</p>

<pre>
&gt; I offer the following anecdote in belated celebration of National
&gt; Punctuation Day (<a href='http://www.nationalpunctuationday.com/'>http://www.nationalpunctuationday.com/</a>) -- which was
&gt; September 24th, 2009, but we can hope that it'll prove to be... um...
&gt; periodic.
</pre>

<p>
You might be interested in this little book:
</p>

<p>
A panda bear walks into a bar and orders a sandwich. The waiter brings
him the sandwich. The panda bear eats it, pulls out a pistol, kills the
waiter, and gets up and starts to walk out.
</p>

<p>
The bartender yells for him to stop. The panda bear asks, "What do you
want?" The bartender replies, "First you come in here, order food, kill
my waiter, then try to go without paying for your food."
</p>

<p>
The panda bear turns around and says, "Hey! I=E2=80=99m a Panda. Look it up=
!"
The bartender goes into the back room and looks up panda bear in the
encyclopedia, which read: "Panda: a bear-like marsupial originating in
Asian regions. Known largely for it=E2=80=99s stark black and white colorin=
g.
Eats, shoots and leaves."
</p>

<p>
<a href='http://en.wikipedia.org/wiki/Eats,_Shoots_&amp;_Leaves'>http://en.wikipedia.org/wiki/Eats,_Shoots_&amp;_Leaves</a>
</p>

<p>
<img src="../gx/smile.png" alt=":)">,
Ren&eacute;.
</p>

<p>

</p>

<p><b>[  <a name="mb-from_the_department_of_pedantry"></a> <a href="misc/lg/from_the_department_of_pedantry.html">Thread continues here (2 messages/2.18kB)</a>  ]</b></p>
<hr />


<!-- Thread anchor: [OT] Meetup? --><a name='ot_meetup'></a>
<h3>[OT] Meetup?</h3>
<p>
<b><p>
Jimmy O'Regan [joregan at gmail.com]

</p>
</b><br />
<b>Fri, 16 Oct 2009 23:57:08 +0100</b>
</p>

<p>
2009/9/15 Rick Moen &lt;rick@linuxmafia.com&gt;:
</p>

<pre>
&gt; Quoting Jimmy O'Regan (joregan@gmail.com):
&gt;
&gt;&gt; I'll be in San Francisco for a couple of days next month (Google
&gt;&gt; Mentor Summit). Will anyone else be around?
&gt;
&gt; Only all the time.
&gt;
&gt; Chez Moen is down about 60 km south of the city of San Francisco,
&gt; at the base of the San Francisco Peninsula, close to Stanford
&gt; University. Â I don't very often get to San Francisco, but certainly
&gt; can/will in order to rendezvous and spend time.
&gt;
</pre>

<p>
With less than a week left, I just now took the time to look at a map
and see where I'll /really/ be; turns out it's Sunnyvale, which is
much closer to Stanford <img src="../gx/smile.png" alt=":)">
</p>

<pre>-- 
&lt;Leftmost&gt; jimregan, that's because deep inside you, you are evil.
&lt;Leftmost&gt; Also not-so-deep inside you.
</pre>

<p>

</p>

<p><b>[  <a name="mb-ot_meetup"></a> <a href="misc/lg/ot_meetup.html">Thread continues here (6 messages/5.67kB)</a>  ]</b></p>
<hr />


<!-- Thread anchor: Power management by sonar --><a name='power_management_by_sonar'></a>
<h3>Power management by sonar</h3>
<p>
<b><p>
Jimmy O'Regan [joregan at gmail.com]

</p>
</b><br />
<b>Thu, 15 Oct 2009 23:46:34 +0100</b>
</p>

<p>
 From this Slashdot story:
<a href='http://hardware.slashdot.org/story/09/10/15/2121214/Sonar-Software-Detects-Laptop-User-Presence?from=rss'>http://hardware.slashdot.org/story/09/10[...]re-Detects-Laptop-User-Presence?from=rss</a>
</p>

<p>
Software here: <a href='http://stevetarzia.com/sonar/'>http://stevetarzia.com/sonar/</a>
</p>

<p>
I'm not really interested in the power management side of things so
much as the scope it provides for a Halloween prank...
Trick or treat!
</p>

<pre>-- 
&lt;Leftmost&gt; jimregan, that's because deep inside you, you are evil.
&lt;Leftmost&gt; Also not-so-deep inside you.
</pre>

<p>

</p>

<hr />


<!-- Thread anchor: Meetup --><a name='meetup'></a>
<h3>Meetup</h3>
<p>
<b><p>
Jimmy O'Regan [joregan at gmail.com]

</p>
</b><br />
<b>Sat, 24 Oct 2009 18:14:04 +0100</b>
</p>

<p>
Hi.
I'm in Sunnyvale now. I think I should be around after 6, if anyone  
can suggest a good meeting place. 
</p>

<p>

</p>

<p><b>[  <a name="mb-meetup"></a> <a href="misc/lg/meetup.html">Thread continues here (4 messages/7.46kB)</a>  ]</b></p>
<hr />


<br clear="all" />

<script type='text/javascript'>
digg_url = 'http://linuxgazette.net/168/lg_launderette.html';
digg_title = 'The Linux Launderette';
digg_bodytext = '<p>In this month\'s Linux Gazette, \'The Linux Launderette\' covers the following topics:<br>From the Department of Pedantry<br>[OT] Meetup?<br>Power management by sonar<br>Meetup<br></p>';
digg_topic = 'linux_unix';
</script>
<script src="http://digg.com/tools/diggthis.js" type="text/javascript"></script>

</p>

<p class="talkback">
Talkback: <a
href="mailto:tag@lists.linuxgazette.net?subject=Talkback:168/lg_launderette.html">Discuss this article with The Answer Gang</a>
</p>

<!-- *** BEGIN author bio *** -->
<!-- *** END author bio *** -->

<div id="articlefooter">


<p>
Published in Issue 168 of Linux Gazette, November 2009
</p>

</div>
</div>


<img src="../gx/tux_86x95_indexed.png" id="tux" alt="Tux"/>

<br />

<script src="http://www.google-analytics.com/urchin.js"
type="text/javascript">
</script>
<script type="text/javascript">
_uacct = "UA-1204316-1";
urchinTracker();
</script>

</body>
</html>

